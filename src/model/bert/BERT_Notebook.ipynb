{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_Notebook",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t38wMRBO_LYX",
        "colab_type": "text"
      },
      "source": [
        "# Fake user classfication using BERT\n",
        "\n",
        "In this notebook, we test our hypothesis that the use of semantic information of tweets (using BERT sentence encoding) will improve the fake user classification accuracy.\n",
        "\n",
        "We have created two deep neural networks as follows:\n",
        "\n",
        "1.   Where the input is just profile features (like geolocation, profile picture, basic information, etc.)\n",
        "2.   Input is a combination of profile features and BERT sentence encoding of user tweets\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TT6zu_mV5c2L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.layers import Dense, Input, concatenate\n",
        "from keras.models import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nknpsKATDsym",
        "colab_type": "text"
      },
      "source": [
        "We used this repository: https://github.com/hanxiao/bert-as-service to get BERT encodings for user tweets. It has been saved in bert.csv file.\n",
        "\n",
        "In the below section, the data file is being read. The BERT features are normalized (min-max) and training/validation sets are created. The resulting dataframe contains 800 features (32 profile features + 768 columns for BERT encodings)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiFS_M9X59CJ",
        "colab_type": "code",
        "outputId": "9dba900a-6471-4e06-df6a-e915be6c74ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        }
      },
      "source": [
        "bert_embedding_size = 768\n",
        "\n",
        "def remap_fields(df):\n",
        "    for name, dtype in zip(list(df), df.dtypes):\n",
        "        \n",
        "        if dtype == 'object':\n",
        "            df[name] = df[name].map( lambda x: 1 if  x else 0)\n",
        "    df.fillna(0, inplace = True)\n",
        "    return df\n",
        "\n",
        "'''\n",
        "  load bert data with bert embeddings\n",
        "'''\n",
        "data = pd.read_csv('../../data/bert.csv')\n",
        "data = remap_fields(data)\n",
        "print(data.sample(1))\n",
        "\n",
        "def get_dataset():\n",
        "    '''\n",
        "        normalize data\n",
        "    '''\n",
        "    normalized_data = data.copy()\n",
        "    for i in range(bert_embedding_size):\n",
        "        col_name = 'bert_' + str(i)\n",
        "        max_col_val = data[col_name].max()\n",
        "        min_col_val = data[col_name].min()\n",
        "\n",
        "        normalized_data[col_name] = (data[col_name] - min_col_val) / (max_col_val - min_col_val)\n",
        "      \n",
        "    '''\n",
        "        create test and train split\n",
        "    '''\n",
        "    train_x, test_x, _, _ = train_test_split(normalized_data, normalized_data.label,  stratify =normalized_data.label)\n",
        "    train_y = train_x.label\n",
        "    test_y = test_x.label\n",
        "\n",
        "    train_x.drop(['Unnamed: 0', 'label', 'id', 'tweet', 'verified'], axis = 1, inplace = True)\n",
        "    test_x.drop(['Unnamed: 0', 'label', 'id', 'tweet', 'verified'], axis = 1, inplace = True)\n",
        "\n",
        "    return train_x, train_y, test_x, test_y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (9,11,17,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "     Unnamed: 0         id  name  ...  bert_765  bert_766  bert_767\n",
            "353         353  525965404     1  ... -0.421459  0.065046 -0.149392\n",
            "\n",
            "[1 rows x 805 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkRevw2Y5mRa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "    define recall, precision, and f1 score\n",
        "'''\n",
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSJ_6Z1qAqdo",
        "colab_type": "text"
      },
      "source": [
        "# Deep neural network - Profile features\n",
        "\n",
        "Here, we create a neural network model with one input layer, 2 hidden layers, and one output layer. The input are just profile features (dimension=32).\n",
        "\n",
        "We have used the Adam optimizer and Binary Cross-Entropy loss function. We performed a five-fold cross validation and following are the results (averaged over the folds):\n",
        "\n",
        "**Accuracy: 0.90343137, F1-score: 0.91886296**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PC0y7RCV_zpx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_base_model(profile_dim=32):\n",
        "    '''\n",
        "        input for profile network\n",
        "    '''\n",
        "    profile_input = Input(shape=(profile_dim,))\n",
        "\n",
        "    output = Dense(32, activation='relu')(profile_input)\n",
        "    output = Dense(16, activation='relu')(output)\n",
        "    output = Dense(1, activation='sigmoid')(output)\n",
        "\n",
        "    model = Model(inputs=[profile_input], outputs=[output])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc', f1_m])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pDCuWnHADpd",
        "colab_type": "code",
        "outputId": "7d471129-98eb-4b1c-b577-07a48b4babb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "cross_val_split = 5\n",
        "cross_val_metrics = []\n",
        "\n",
        "for i in range(cross_val_split):\n",
        "    '''\n",
        "        get data\n",
        "    '''\n",
        "    train_x, train_y, test_x, test_y = get_dataset()\n",
        "\n",
        "    '''\n",
        "        build neural network model\n",
        "    '''\n",
        "    model = build_base_model()\n",
        "    model.summary()\n",
        "\n",
        "    '''\n",
        "        get only profile features from train/validation data\n",
        "    '''\n",
        "    train_split = np.hsplit(train_x, np.array([32, 800]))[0]\n",
        "    test_split = np.hsplit(test_x, np.array([32, 800]))[0]\n",
        "    model.fit(x=train_split, y=train_y, batch_size=32, shuffle=True, epochs=100)\n",
        "\n",
        "    val_res = model.evaluate(test_split, test_y)\n",
        "    cross_val_metrics.append(np.array(val_res))\n",
        "\n",
        "print(\"(Loss, Accuracy, F1-score) after 5-fold cross validation\", np.sum(cross_val_metrics, axis=0)/cross_val_split)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4117: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_15 (InputLayer)        (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_50 (Dense)             (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_51 (Dense)             (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_52 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 1,601\n",
            "Trainable params: 1,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "11015/11015 [==============================] - 3s 266us/step - loss: 2.6422 - acc: 0.7994 - f1_m: 0.8236\n",
            "Epoch 2/100\n",
            "11015/11015 [==============================] - 2s 154us/step - loss: 2.0553 - acc: 0.8588 - f1_m: 0.8740\n",
            "Epoch 3/100\n",
            "11015/11015 [==============================] - 2s 159us/step - loss: 2.0534 - acc: 0.8596 - f1_m: 0.8750\n",
            "Epoch 4/100\n",
            "11015/11015 [==============================] - 2s 171us/step - loss: 2.0168 - acc: 0.8635 - f1_m: 0.8786\n",
            "Epoch 5/100\n",
            "11015/11015 [==============================] - 2s 169us/step - loss: 2.1251 - acc: 0.8563 - f1_m: 0.8754\n",
            "Epoch 6/100\n",
            "11015/11015 [==============================] - 2s 173us/step - loss: 2.0125 - acc: 0.8640 - f1_m: 0.8844\n",
            "Epoch 7/100\n",
            "11015/11015 [==============================] - 2s 167us/step - loss: 1.8830 - acc: 0.8741 - f1_m: 0.8891\n",
            "Epoch 8/100\n",
            "11015/11015 [==============================] - 2s 170us/step - loss: 1.7653 - acc: 0.8833 - f1_m: 0.8971\n",
            "Epoch 9/100\n",
            "11015/11015 [==============================] - 2s 174us/step - loss: 1.7793 - acc: 0.8818 - f1_m: 0.8981\n",
            "Epoch 10/100\n",
            "11015/11015 [==============================] - 2s 167us/step - loss: 1.8239 - acc: 0.8778 - f1_m: 0.8953\n",
            "Epoch 11/100\n",
            "11015/11015 [==============================] - 2s 175us/step - loss: 1.7303 - acc: 0.8847 - f1_m: 0.8987\n",
            "Epoch 12/100\n",
            "11015/11015 [==============================] - 2s 161us/step - loss: 1.7942 - acc: 0.8814 - f1_m: 0.8959\n",
            "Epoch 13/100\n",
            "11015/11015 [==============================] - 2s 159us/step - loss: 1.7622 - acc: 0.8790 - f1_m: 0.8921\n",
            "Epoch 14/100\n",
            "11015/11015 [==============================] - 2s 177us/step - loss: 1.7788 - acc: 0.8827 - f1_m: 0.8965\n",
            "Epoch 15/100\n",
            "11015/11015 [==============================] - 2s 174us/step - loss: 1.7263 - acc: 0.8856 - f1_m: 0.9003\n",
            "Epoch 16/100\n",
            "11015/11015 [==============================] - 2s 171us/step - loss: 1.7357 - acc: 0.8855 - f1_m: 0.8991\n",
            "Epoch 17/100\n",
            "11015/11015 [==============================] - 2s 166us/step - loss: 1.7349 - acc: 0.8855 - f1_m: 0.8996\n",
            "Epoch 18/100\n",
            "11015/11015 [==============================] - 2s 161us/step - loss: 1.6985 - acc: 0.8881 - f1_m: 0.9025\n",
            "Epoch 19/100\n",
            "11015/11015 [==============================] - 2s 164us/step - loss: 1.7029 - acc: 0.8873 - f1_m: 0.9034\n",
            "Epoch 20/100\n",
            "11015/11015 [==============================] - 2s 157us/step - loss: 2.0538 - acc: 0.8666 - f1_m: 0.8933\n",
            "Epoch 21/100\n",
            "11015/11015 [==============================] - 2s 159us/step - loss: 1.7688 - acc: 0.8833 - f1_m: 0.9024\n",
            "Epoch 22/100\n",
            "11015/11015 [==============================] - 2s 144us/step - loss: 1.6893 - acc: 0.8904 - f1_m: 0.9040\n",
            "Epoch 23/100\n",
            "11015/11015 [==============================] - 2s 162us/step - loss: 1.6907 - acc: 0.8886 - f1_m: 0.9032\n",
            "Epoch 24/100\n",
            "11015/11015 [==============================] - 2s 162us/step - loss: 1.6816 - acc: 0.8890 - f1_m: 0.9034\n",
            "Epoch 25/100\n",
            "11015/11015 [==============================] - 2s 161us/step - loss: 1.6177 - acc: 0.8929 - f1_m: 0.9109\n",
            "Epoch 26/100\n",
            "11015/11015 [==============================] - 2s 166us/step - loss: 1.7244 - acc: 0.8871 - f1_m: 0.9013\n",
            "Epoch 27/100\n",
            "11015/11015 [==============================] - 2s 166us/step - loss: 1.7190 - acc: 0.8871 - f1_m: 0.9016\n",
            "Epoch 28/100\n",
            "11015/11015 [==============================] - 2s 156us/step - loss: 1.7554 - acc: 0.8855 - f1_m: 0.8993\n",
            "Epoch 29/100\n",
            "11015/11015 [==============================] - 2s 182us/step - loss: 1.7467 - acc: 0.8855 - f1_m: 0.8990\n",
            "Epoch 30/100\n",
            "11015/11015 [==============================] - 2s 158us/step - loss: 1.7389 - acc: 0.8872 - f1_m: 0.9007\n",
            "Epoch 31/100\n",
            "11015/11015 [==============================] - 2s 158us/step - loss: 1.7501 - acc: 0.8869 - f1_m: 0.8990\n",
            "Epoch 32/100\n",
            "11015/11015 [==============================] - 2s 161us/step - loss: 1.7418 - acc: 0.8871 - f1_m: 0.9004\n",
            "Epoch 33/100\n",
            "11015/11015 [==============================] - 2s 180us/step - loss: 1.7536 - acc: 0.8843 - f1_m: 0.8974\n",
            "Epoch 34/100\n",
            "11015/11015 [==============================] - 2s 165us/step - loss: 1.6981 - acc: 0.8896 - f1_m: 0.9032\n",
            "Epoch 35/100\n",
            "11015/11015 [==============================] - 2s 176us/step - loss: 1.6886 - acc: 0.8902 - f1_m: 0.9038\n",
            "Epoch 36/100\n",
            "11015/11015 [==============================] - 2s 166us/step - loss: 1.7160 - acc: 0.8881 - f1_m: 0.9020\n",
            "Epoch 37/100\n",
            "11015/11015 [==============================] - 2s 162us/step - loss: 1.8209 - acc: 0.8826 - f1_m: 0.8974\n",
            "Epoch 38/100\n",
            "11015/11015 [==============================] - 2s 174us/step - loss: 1.7211 - acc: 0.8892 - f1_m: 0.9019\n",
            "Epoch 39/100\n",
            "11015/11015 [==============================] - 2s 163us/step - loss: 1.7059 - acc: 0.8890 - f1_m: 0.9024\n",
            "Epoch 40/100\n",
            "11015/11015 [==============================] - 2s 189us/step - loss: 1.7382 - acc: 0.8864 - f1_m: 0.9004\n",
            "Epoch 41/100\n",
            "11015/11015 [==============================] - 2s 183us/step - loss: 1.7108 - acc: 0.8896 - f1_m: 0.9026\n",
            "Epoch 42/100\n",
            "11015/11015 [==============================] - 2s 171us/step - loss: 1.7045 - acc: 0.8898 - f1_m: 0.9030\n",
            "Epoch 43/100\n",
            "11015/11015 [==============================] - 2s 163us/step - loss: 1.6923 - acc: 0.8890 - f1_m: 0.9024\n",
            "Epoch 44/100\n",
            "11015/11015 [==============================] - 2s 175us/step - loss: 1.6883 - acc: 0.8903 - f1_m: 0.9034\n",
            "Epoch 45/100\n",
            "11015/11015 [==============================] - 2s 170us/step - loss: 1.6966 - acc: 0.8896 - f1_m: 0.9027\n",
            "Epoch 46/100\n",
            "11015/11015 [==============================] - 2s 169us/step - loss: 1.6851 - acc: 0.8898 - f1_m: 0.9032\n",
            "Epoch 47/100\n",
            "11015/11015 [==============================] - 2s 159us/step - loss: 1.7012 - acc: 0.8872 - f1_m: 0.9013\n",
            "Epoch 48/100\n",
            "11015/11015 [==============================] - 2s 157us/step - loss: 1.5925 - acc: 0.8941 - f1_m: 0.9093\n",
            "Epoch 49/100\n",
            "11015/11015 [==============================] - 2s 155us/step - loss: 1.7042 - acc: 0.8875 - f1_m: 0.9030\n",
            "Epoch 50/100\n",
            "11015/11015 [==============================] - 2s 177us/step - loss: 1.6861 - acc: 0.8902 - f1_m: 0.9036\n",
            "Epoch 51/100\n",
            "11015/11015 [==============================] - 2s 181us/step - loss: 1.6932 - acc: 0.8902 - f1_m: 0.9028\n",
            "Epoch 52/100\n",
            "11015/11015 [==============================] - 2s 183us/step - loss: 1.6818 - acc: 0.8913 - f1_m: 0.9047\n",
            "Epoch 53/100\n",
            "11015/11015 [==============================] - 2s 176us/step - loss: 1.6765 - acc: 0.8910 - f1_m: 0.9037\n",
            "Epoch 54/100\n",
            "11015/11015 [==============================] - 2s 172us/step - loss: 1.6728 - acc: 0.8913 - f1_m: 0.9041\n",
            "Epoch 55/100\n",
            "11015/11015 [==============================] - 2s 167us/step - loss: 1.6741 - acc: 0.8908 - f1_m: 0.9040\n",
            "Epoch 56/100\n",
            "11015/11015 [==============================] - 2s 159us/step - loss: 1.6817 - acc: 0.8910 - f1_m: 0.9039\n",
            "Epoch 57/100\n",
            "11015/11015 [==============================] - 2s 158us/step - loss: 1.6917 - acc: 0.8902 - f1_m: 0.9022\n",
            "Epoch 58/100\n",
            "11015/11015 [==============================] - 2s 157us/step - loss: 1.7024 - acc: 0.8898 - f1_m: 0.9026\n",
            "Epoch 59/100\n",
            "11015/11015 [==============================] - 2s 157us/step - loss: 1.6917 - acc: 0.8896 - f1_m: 0.9023\n",
            "Epoch 60/100\n",
            "11015/11015 [==============================] - 2s 169us/step - loss: 1.6784 - acc: 0.8911 - f1_m: 0.9045\n",
            "Epoch 61/100\n",
            "11015/11015 [==============================] - 2s 158us/step - loss: 1.6799 - acc: 0.8896 - f1_m: 0.9021\n",
            "Epoch 62/100\n",
            "11015/11015 [==============================] - 2s 179us/step - loss: 1.6721 - acc: 0.8905 - f1_m: 0.9033\n",
            "Epoch 63/100\n",
            "11015/11015 [==============================] - 2s 158us/step - loss: 1.6261 - acc: 0.8924 - f1_m: 0.9069\n",
            "Epoch 64/100\n",
            "11015/11015 [==============================] - 2s 159us/step - loss: 1.6020 - acc: 0.8936 - f1_m: 0.9072\n",
            "Epoch 65/100\n",
            "11015/11015 [==============================] - 2s 161us/step - loss: 1.5717 - acc: 0.8961 - f1_m: 0.9085\n",
            "Epoch 66/100\n",
            "11015/11015 [==============================] - 2s 171us/step - loss: 1.5543 - acc: 0.8974 - f1_m: 0.9108\n",
            "Epoch 67/100\n",
            "11015/11015 [==============================] - 2s 167us/step - loss: 1.5970 - acc: 0.8949 - f1_m: 0.9113\n",
            "Epoch 68/100\n",
            "11015/11015 [==============================] - 2s 154us/step - loss: 2.0963 - acc: 0.8635 - f1_m: 0.8918\n",
            "Epoch 69/100\n",
            "11015/11015 [==============================] - 2s 158us/step - loss: 2.0825 - acc: 0.8639 - f1_m: 0.8933\n",
            "Epoch 70/100\n",
            "11015/11015 [==============================] - 2s 160us/step - loss: 1.8338 - acc: 0.8802 - f1_m: 0.9042\n",
            "Epoch 71/100\n",
            "11015/11015 [==============================] - 2s 167us/step - loss: 1.6671 - acc: 0.8899 - f1_m: 0.9126\n",
            "Epoch 72/100\n",
            "11015/11015 [==============================] - 2s 173us/step - loss: 1.6334 - acc: 0.8919 - f1_m: 0.9055\n",
            "Epoch 73/100\n",
            "11015/11015 [==============================] - 2s 157us/step - loss: 1.5168 - acc: 0.8985 - f1_m: 0.9120\n",
            "Epoch 74/100\n",
            "11015/11015 [==============================] - 2s 153us/step - loss: 1.5158 - acc: 0.8989 - f1_m: 0.9125\n",
            "Epoch 75/100\n",
            "11015/11015 [==============================] - 2s 162us/step - loss: 1.5596 - acc: 0.8964 - f1_m: 0.9095\n",
            "Epoch 76/100\n",
            "11015/11015 [==============================] - 2s 173us/step - loss: 1.5610 - acc: 0.8961 - f1_m: 0.9114\n",
            "Epoch 77/100\n",
            "11015/11015 [==============================] - 2s 166us/step - loss: 1.6156 - acc: 0.8917 - f1_m: 0.9081\n",
            "Epoch 78/100\n",
            "11015/11015 [==============================] - 2s 176us/step - loss: 1.5727 - acc: 0.8950 - f1_m: 0.9102\n",
            "Epoch 79/100\n",
            "11015/11015 [==============================] - 2s 181us/step - loss: 1.3490 - acc: 0.9076 - f1_m: 0.9224\n",
            "Epoch 80/100\n",
            "11015/11015 [==============================] - 2s 165us/step - loss: 1.4958 - acc: 0.8997 - f1_m: 0.9133\n",
            "Epoch 81/100\n",
            "11015/11015 [==============================] - 2s 179us/step - loss: 0.9863 - acc: 0.9276 - f1_m: 0.9397\n",
            "Epoch 82/100\n",
            "11015/11015 [==============================] - 2s 164us/step - loss: 1.1033 - acc: 0.9223 - f1_m: 0.9357\n",
            "Epoch 83/100\n",
            "11015/11015 [==============================] - 2s 168us/step - loss: 1.0884 - acc: 0.9228 - f1_m: 0.9353\n",
            "Epoch 84/100\n",
            "11015/11015 [==============================] - 2s 160us/step - loss: 1.4511 - acc: 0.9020 - f1_m: 0.9156\n",
            "Epoch 85/100\n",
            "11015/11015 [==============================] - 2s 168us/step - loss: 1.2737 - acc: 0.9125 - f1_m: 0.9257\n",
            "Epoch 86/100\n",
            "11015/11015 [==============================] - 2s 175us/step - loss: 1.2725 - acc: 0.9119 - f1_m: 0.9240\n",
            "Epoch 87/100\n",
            "11015/11015 [==============================] - 2s 151us/step - loss: 1.4325 - acc: 0.9016 - f1_m: 0.9155\n",
            "Epoch 88/100\n",
            "11015/11015 [==============================] - 2s 161us/step - loss: 1.5118 - acc: 0.9004 - f1_m: 0.9129\n",
            "Epoch 89/100\n",
            "11015/11015 [==============================] - 2s 163us/step - loss: 1.3399 - acc: 0.9083 - f1_m: 0.9214\n",
            "Epoch 90/100\n",
            "11015/11015 [==============================] - 2s 157us/step - loss: 1.0979 - acc: 0.9204 - f1_m: 0.9327\n",
            "Epoch 91/100\n",
            "11015/11015 [==============================] - 2s 159us/step - loss: 1.5301 - acc: 0.8978 - f1_m: 0.9104\n",
            "Epoch 92/100\n",
            "11015/11015 [==============================] - 2s 163us/step - loss: 1.1728 - acc: 0.9177 - f1_m: 0.9306\n",
            "Epoch 93/100\n",
            "11015/11015 [==============================] - 2s 154us/step - loss: 0.9527 - acc: 0.9293 - f1_m: 0.9408\n",
            "Epoch 94/100\n",
            "11015/11015 [==============================] - 2s 157us/step - loss: 0.8685 - acc: 0.9325 - f1_m: 0.9440\n",
            "Epoch 95/100\n",
            "11015/11015 [==============================] - 2s 171us/step - loss: 0.7950 - acc: 0.9388 - f1_m: 0.9494\n",
            "Epoch 96/100\n",
            "11015/11015 [==============================] - 2s 174us/step - loss: 0.9416 - acc: 0.9286 - f1_m: 0.9400\n",
            "Epoch 97/100\n",
            "11015/11015 [==============================] - 2s 169us/step - loss: 0.8720 - acc: 0.9319 - f1_m: 0.9427\n",
            "Epoch 98/100\n",
            "11015/11015 [==============================] - 2s 162us/step - loss: 0.9410 - acc: 0.9273 - f1_m: 0.9385\n",
            "Epoch 99/100\n",
            "11015/11015 [==============================] - 2s 165us/step - loss: 0.9564 - acc: 0.9280 - f1_m: 0.9396\n",
            "Epoch 100/100\n",
            "11015/11015 [==============================] - 2s 165us/step - loss: 0.9343 - acc: 0.9297 - f1_m: 0.9404\n",
            "3672/3672 [==============================] - 1s 149us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4117: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_16 (InputLayer)        (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_53 (Dense)             (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_54 (Dense)             (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_55 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 1,601\n",
            "Trainable params: 1,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "11015/11015 [==============================] - 3s 253us/step - loss: 3.5242 - acc: 0.7690 - f1_m: 0.8400\n",
            "Epoch 2/100\n",
            "11015/11015 [==============================] - 2s 162us/step - loss: 2.4265 - acc: 0.8350 - f1_m: 0.8738\n",
            "Epoch 3/100\n",
            "11015/11015 [==============================] - 2s 152us/step - loss: 1.7859 - acc: 0.8817 - f1_m: 0.8962\n",
            "Epoch 4/100\n",
            "11015/11015 [==============================] - 2s 155us/step - loss: 1.6808 - acc: 0.8869 - f1_m: 0.9036\n",
            "Epoch 5/100\n",
            "11015/11015 [==============================] - 2s 166us/step - loss: 1.7144 - acc: 0.8864 - f1_m: 0.9007\n",
            "Epoch 6/100\n",
            "11015/11015 [==============================] - 2s 174us/step - loss: 1.6176 - acc: 0.8925 - f1_m: 0.9072\n",
            "Epoch 7/100\n",
            "11015/11015 [==============================] - 2s 168us/step - loss: 1.7352 - acc: 0.8854 - f1_m: 0.8988\n",
            "Epoch 8/100\n",
            "11015/11015 [==============================] - 2s 170us/step - loss: 1.7452 - acc: 0.8854 - f1_m: 0.8995\n",
            "Epoch 9/100\n",
            "11015/11015 [==============================] - 2s 159us/step - loss: 1.7611 - acc: 0.8844 - f1_m: 0.8976\n",
            "Epoch 10/100\n",
            "11015/11015 [==============================] - 2s 168us/step - loss: 1.7391 - acc: 0.8860 - f1_m: 0.9020\n",
            "Epoch 11/100\n",
            "11015/11015 [==============================] - 2s 171us/step - loss: 1.7899 - acc: 0.8825 - f1_m: 0.9029\n",
            "Epoch 12/100\n",
            "11015/11015 [==============================] - 2s 155us/step - loss: 2.1581 - acc: 0.8560 - f1_m: 0.8829\n",
            "Epoch 13/100\n",
            "11015/11015 [==============================] - 2s 160us/step - loss: 1.5474 - acc: 0.8986 - f1_m: 0.9140\n",
            "Epoch 14/100\n",
            "11015/11015 [==============================] - 2s 174us/step - loss: 1.4487 - acc: 0.9042 - f1_m: 0.9210\n",
            "Epoch 15/100\n",
            "11015/11015 [==============================] - 2s 174us/step - loss: 1.7121 - acc: 0.8883 - f1_m: 0.9027\n",
            "Epoch 16/100\n",
            "11015/11015 [==============================] - 2s 179us/step - loss: 1.7483 - acc: 0.8852 - f1_m: 0.8984\n",
            "Epoch 17/100\n",
            "11015/11015 [==============================] - 2s 171us/step - loss: 1.7417 - acc: 0.8878 - f1_m: 0.9010\n",
            "Epoch 18/100\n",
            "11015/11015 [==============================] - 2s 165us/step - loss: 1.6363 - acc: 0.8934 - f1_m: 0.9088\n",
            "Epoch 19/100\n",
            "11015/11015 [==============================] - 2s 156us/step - loss: 1.5829 - acc: 0.8959 - f1_m: 0.9105\n",
            "Epoch 20/100\n",
            "11015/11015 [==============================] - 2s 158us/step - loss: 1.7111 - acc: 0.8891 - f1_m: 0.9025\n",
            "Epoch 21/100\n",
            "11015/11015 [==============================] - 2s 182us/step - loss: 1.7135 - acc: 0.8886 - f1_m: 0.9020\n",
            "Epoch 22/100\n",
            "11015/11015 [==============================] - 2s 158us/step - loss: 1.7210 - acc: 0.8885 - f1_m: 0.9026\n",
            "Epoch 23/100\n",
            "11015/11015 [==============================] - 2s 158us/step - loss: 1.7177 - acc: 0.8881 - f1_m: 0.9017\n",
            "Epoch 24/100\n",
            "11015/11015 [==============================] - 2s 161us/step - loss: 1.6779 - acc: 0.8896 - f1_m: 0.9039\n",
            "Epoch 25/100\n",
            "11015/11015 [==============================] - 2s 171us/step - loss: 1.6964 - acc: 0.8883 - f1_m: 0.9039\n",
            "Epoch 26/100\n",
            "11015/11015 [==============================] - 2s 181us/step - loss: 1.5930 - acc: 0.8956 - f1_m: 0.9116\n",
            "Epoch 27/100\n",
            "11015/11015 [==============================] - 2s 182us/step - loss: 1.6504 - acc: 0.8929 - f1_m: 0.9066\n",
            "Epoch 28/100\n",
            "11015/11015 [==============================] - 2s 177us/step - loss: 1.5869 - acc: 0.8960 - f1_m: 0.9099\n",
            "Epoch 29/100\n",
            "11015/11015 [==============================] - 2s 165us/step - loss: 1.6299 - acc: 0.8934 - f1_m: 0.9094\n",
            "Epoch 30/100\n",
            "11015/11015 [==============================] - 2s 171us/step - loss: 1.3867 - acc: 0.9089 - f1_m: 0.9242\n",
            "Epoch 31/100\n",
            "11015/11015 [==============================] - 2s 162us/step - loss: 1.4219 - acc: 0.9057 - f1_m: 0.9221\n",
            "Epoch 32/100\n",
            "11015/11015 [==============================] - 2s 156us/step - loss: 1.4783 - acc: 0.9038 - f1_m: 0.9208\n",
            "Epoch 33/100\n",
            "11015/11015 [==============================] - 2s 158us/step - loss: 1.5387 - acc: 0.8988 - f1_m: 0.9166\n",
            "Epoch 34/100\n",
            "11015/11015 [==============================] - 2s 161us/step - loss: 1.3405 - acc: 0.9118 - f1_m: 0.9271\n",
            "Epoch 35/100\n",
            "11015/11015 [==============================] - 2s 174us/step - loss: 1.4879 - acc: 0.9008 - f1_m: 0.9188\n",
            "Epoch 36/100\n",
            "11015/11015 [==============================] - 2s 174us/step - loss: 1.3260 - acc: 0.9123 - f1_m: 0.9262\n",
            "Epoch 37/100\n",
            "11015/11015 [==============================] - 2s 165us/step - loss: 1.5166 - acc: 0.9000 - f1_m: 0.9158\n",
            "Epoch 38/100\n",
            "11015/11015 [==============================] - 2s 166us/step - loss: 1.3165 - acc: 0.9135 - f1_m: 0.9278\n",
            "Epoch 39/100\n",
            "11015/11015 [==============================] - 2s 170us/step - loss: 1.7228 - acc: 0.8883 - f1_m: 0.9013\n",
            "Epoch 40/100\n",
            "11015/11015 [==============================] - 2s 156us/step - loss: 1.6987 - acc: 0.8898 - f1_m: 0.9034\n",
            "Epoch 41/100\n",
            "11015/11015 [==============================] - 2s 185us/step - loss: 1.7016 - acc: 0.8899 - f1_m: 0.9027\n",
            "Epoch 42/100\n",
            "11015/11015 [==============================] - 2s 174us/step - loss: 1.7192 - acc: 0.8879 - f1_m: 0.9013\n",
            "Epoch 43/100\n",
            "11015/11015 [==============================] - 2s 166us/step - loss: 1.7062 - acc: 0.8890 - f1_m: 0.9029\n",
            "Epoch 44/100\n",
            "11015/11015 [==============================] - 2s 170us/step - loss: 1.7091 - acc: 0.8891 - f1_m: 0.9016\n",
            "Epoch 45/100\n",
            "11015/11015 [==============================] - 2s 176us/step - loss: 1.7338 - acc: 0.8868 - f1_m: 0.8996\n",
            "Epoch 46/100\n",
            "11015/11015 [==============================] - 2s 168us/step - loss: 1.7110 - acc: 0.8892 - f1_m: 0.9028\n",
            "Epoch 47/100\n",
            "11015/11015 [==============================] - 2s 160us/step - loss: 1.7154 - acc: 0.8889 - f1_m: 0.9019\n",
            "Epoch 48/100\n",
            "11015/11015 [==============================] - 2s 167us/step - loss: 1.7032 - acc: 0.8896 - f1_m: 0.9027\n",
            "Epoch 49/100\n",
            "11015/11015 [==============================] - 2s 176us/step - loss: 1.7043 - acc: 0.8891 - f1_m: 0.9024\n",
            "Epoch 50/100\n",
            "11015/11015 [==============================] - 2s 158us/step - loss: 1.7090 - acc: 0.8892 - f1_m: 0.9036\n",
            "Epoch 51/100\n",
            "11015/11015 [==============================] - 2s 179us/step - loss: 1.7005 - acc: 0.8896 - f1_m: 0.9029\n",
            "Epoch 52/100\n",
            "11015/11015 [==============================] - 2s 172us/step - loss: 1.6951 - acc: 0.8896 - f1_m: 0.9032\n",
            "Epoch 53/100\n",
            "11015/11015 [==============================] - 2s 173us/step - loss: 1.6958 - acc: 0.8893 - f1_m: 0.9020\n",
            "Epoch 54/100\n",
            "11015/11015 [==============================] - 2s 171us/step - loss: 1.6960 - acc: 0.8888 - f1_m: 0.9025\n",
            "Epoch 55/100\n",
            "11015/11015 [==============================] - 2s 170us/step - loss: 1.7905 - acc: 0.8832 - f1_m: 0.8988\n",
            "Epoch 56/100\n",
            "11015/11015 [==============================] - 2s 162us/step - loss: 1.7004 - acc: 0.8885 - f1_m: 0.9022\n",
            "Epoch 57/100\n",
            "11015/11015 [==============================] - 2s 169us/step - loss: 1.6737 - acc: 0.8899 - f1_m: 0.9047\n",
            "Epoch 58/100\n",
            "11015/11015 [==============================] - 2s 162us/step - loss: 1.6581 - acc: 0.8914 - f1_m: 0.9042\n",
            "Epoch 59/100\n",
            "11015/11015 [==============================] - 2s 167us/step - loss: 1.7456 - acc: 0.8852 - f1_m: 0.9004\n",
            "Epoch 60/100\n",
            "11015/11015 [==============================] - 2s 154us/step - loss: 1.6987 - acc: 0.8891 - f1_m: 0.9014\n",
            "Epoch 61/100\n",
            "11015/11015 [==============================] - 2s 184us/step - loss: 1.6897 - acc: 0.8901 - f1_m: 0.9039\n",
            "Epoch 62/100\n",
            "11015/11015 [==============================] - 2s 170us/step - loss: 1.6895 - acc: 0.8907 - f1_m: 0.9034\n",
            "Epoch 63/100\n",
            "11015/11015 [==============================] - 2s 151us/step - loss: 1.6841 - acc: 0.8904 - f1_m: 0.9039\n",
            "Epoch 64/100\n",
            "11015/11015 [==============================] - 2s 174us/step - loss: 1.6791 - acc: 0.8901 - f1_m: 0.9037\n",
            "Epoch 65/100\n",
            "11015/11015 [==============================] - 2s 163us/step - loss: 1.6995 - acc: 0.8883 - f1_m: 0.9022\n",
            "Epoch 66/100\n",
            "11015/11015 [==============================] - 2s 169us/step - loss: 1.6977 - acc: 0.8896 - f1_m: 0.9032\n",
            "Epoch 67/100\n",
            "11015/11015 [==============================] - 2s 172us/step - loss: 1.6823 - acc: 0.8888 - f1_m: 0.9030\n",
            "Epoch 68/100\n",
            "11015/11015 [==============================] - 2s 172us/step - loss: 1.7452 - acc: 0.8845 - f1_m: 0.8999\n",
            "Epoch 69/100\n",
            "11015/11015 [==============================] - 2s 167us/step - loss: 1.7208 - acc: 0.8885 - f1_m: 0.9018\n",
            "Epoch 70/100\n",
            "11015/11015 [==============================] - 2s 161us/step - loss: 1.7101 - acc: 0.8902 - f1_m: 0.9037\n",
            "Epoch 71/100\n",
            "11015/11015 [==============================] - 2s 175us/step - loss: 1.6976 - acc: 0.8904 - f1_m: 0.9031\n",
            "Epoch 72/100\n",
            "11015/11015 [==============================] - 2s 161us/step - loss: 1.6862 - acc: 0.8910 - f1_m: 0.9046\n",
            "Epoch 73/100\n",
            "11015/11015 [==============================] - 2s 148us/step - loss: 2.0416 - acc: 0.8675 - f1_m: 0.8937\n",
            "Epoch 74/100\n",
            "11015/11015 [==============================] - 2s 151us/step - loss: 1.3301 - acc: 0.9118 - f1_m: 0.9271\n",
            "Epoch 75/100\n",
            "11015/11015 [==============================] - 2s 149us/step - loss: 1.3363 - acc: 0.9124 - f1_m: 0.9280\n",
            "Epoch 76/100\n",
            "11015/11015 [==============================] - 2s 171us/step - loss: 1.3125 - acc: 0.9135 - f1_m: 0.9279\n",
            "Epoch 77/100\n",
            "11015/11015 [==============================] - 2s 176us/step - loss: 1.2155 - acc: 0.9191 - f1_m: 0.9324\n",
            "Epoch 78/100\n",
            "11015/11015 [==============================] - 2s 174us/step - loss: 1.2076 - acc: 0.9191 - f1_m: 0.9329\n",
            "Epoch 79/100\n",
            "11015/11015 [==============================] - 2s 170us/step - loss: 1.2548 - acc: 0.9164 - f1_m: 0.9302\n",
            "Epoch 80/100\n",
            "11015/11015 [==============================] - 2s 161us/step - loss: 1.2791 - acc: 0.9148 - f1_m: 0.9290\n",
            "Epoch 81/100\n",
            "11015/11015 [==============================] - 2s 170us/step - loss: 1.4791 - acc: 0.9031 - f1_m: 0.9163\n",
            "Epoch 82/100\n",
            "11015/11015 [==============================] - 2s 158us/step - loss: 1.6686 - acc: 0.8918 - f1_m: 0.9048\n",
            "Epoch 83/100\n",
            "11015/11015 [==============================] - 2s 159us/step - loss: 1.6675 - acc: 0.8916 - f1_m: 0.9058\n",
            "Epoch 84/100\n",
            "11015/11015 [==============================] - 2s 156us/step - loss: 1.6424 - acc: 0.8929 - f1_m: 0.9063\n",
            "Epoch 85/100\n",
            "11015/11015 [==============================] - 2s 154us/step - loss: 1.6720 - acc: 0.8901 - f1_m: 0.9032\n",
            "Epoch 86/100\n",
            "11015/11015 [==============================] - 2s 169us/step - loss: 1.6823 - acc: 0.8897 - f1_m: 0.9028\n",
            "Epoch 87/100\n",
            "11015/11015 [==============================] - 2s 167us/step - loss: 1.6759 - acc: 0.8906 - f1_m: 0.9036\n",
            "Epoch 88/100\n",
            "11015/11015 [==============================] - 2s 164us/step - loss: 1.6759 - acc: 0.8908 - f1_m: 0.9042\n",
            "Epoch 89/100\n",
            "11015/11015 [==============================] - 2s 171us/step - loss: 1.6661 - acc: 0.8906 - f1_m: 0.9051\n",
            "Epoch 90/100\n",
            "11015/11015 [==============================] - 2s 159us/step - loss: 1.6653 - acc: 0.8902 - f1_m: 0.9042\n",
            "Epoch 91/100\n",
            "11015/11015 [==============================] - 2s 164us/step - loss: 1.6830 - acc: 0.8899 - f1_m: 0.9035\n",
            "Epoch 92/100\n",
            "11015/11015 [==============================] - 2s 164us/step - loss: 1.6684 - acc: 0.8919 - f1_m: 0.9037\n",
            "Epoch 93/100\n",
            "11015/11015 [==============================] - 2s 164us/step - loss: 1.6660 - acc: 0.8914 - f1_m: 0.9036\n",
            "Epoch 94/100\n",
            "11015/11015 [==============================] - 2s 167us/step - loss: 1.6685 - acc: 0.8913 - f1_m: 0.9039\n",
            "Epoch 95/100\n",
            "11015/11015 [==============================] - 2s 157us/step - loss: 1.6642 - acc: 0.8903 - f1_m: 0.9033\n",
            "Epoch 96/100\n",
            "11015/11015 [==============================] - 2s 163us/step - loss: 1.6477 - acc: 0.8897 - f1_m: 0.9042\n",
            "Epoch 97/100\n",
            "11015/11015 [==============================] - 2s 173us/step - loss: 1.7029 - acc: 0.8879 - f1_m: 0.9033\n",
            "Epoch 98/100\n",
            "11015/11015 [==============================] - 2s 168us/step - loss: 1.4550 - acc: 0.9018 - f1_m: 0.9187\n",
            "Epoch 99/100\n",
            "11015/11015 [==============================] - 2s 167us/step - loss: 1.3132 - acc: 0.9107 - f1_m: 0.9279\n",
            "Epoch 100/100\n",
            "11015/11015 [==============================] - 2s 168us/step - loss: 1.3892 - acc: 0.9070 - f1_m: 0.9200\n",
            "3672/3672 [==============================] - 1s 149us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4117: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_17 (InputLayer)        (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_56 (Dense)             (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_57 (Dense)             (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_58 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 1,601\n",
            "Trainable params: 1,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "11015/11015 [==============================] - 3s 255us/step - loss: 2.8481 - acc: 0.7985 - f1_m: 0.8437\n",
            "Epoch 2/100\n",
            "11015/11015 [==============================] - 2s 178us/step - loss: 1.7641 - acc: 0.8809 - f1_m: 0.8957\n",
            "Epoch 3/100\n",
            "11015/11015 [==============================] - 2s 177us/step - loss: 1.7270 - acc: 0.8827 - f1_m: 0.8978\n",
            "Epoch 4/100\n",
            "11015/11015 [==============================] - 2s 174us/step - loss: 1.6839 - acc: 0.8846 - f1_m: 0.8993\n",
            "Epoch 5/100\n",
            "11015/11015 [==============================] - 2s 172us/step - loss: 1.8562 - acc: 0.8734 - f1_m: 0.8904\n",
            "Epoch 6/100\n",
            "11015/11015 [==============================] - 2s 167us/step - loss: 1.7220 - acc: 0.8840 - f1_m: 0.8988\n",
            "Epoch 7/100\n",
            "11015/11015 [==============================] - 2s 170us/step - loss: 1.6972 - acc: 0.8843 - f1_m: 0.8996\n",
            "Epoch 8/100\n",
            "11015/11015 [==============================] - 2s 176us/step - loss: 1.6844 - acc: 0.8857 - f1_m: 0.9005\n",
            "Epoch 9/100\n",
            "11015/11015 [==============================] - 2s 162us/step - loss: 1.6772 - acc: 0.8867 - f1_m: 0.9009\n",
            "Epoch 10/100\n",
            "11015/11015 [==============================] - 2s 166us/step - loss: 1.7243 - acc: 0.8823 - f1_m: 0.8960\n",
            "Epoch 11/100\n",
            "11015/11015 [==============================] - 2s 160us/step - loss: 1.6951 - acc: 0.8876 - f1_m: 0.9021\n",
            "Epoch 12/100\n",
            "11015/11015 [==============================] - 2s 185us/step - loss: 1.6829 - acc: 0.8885 - f1_m: 0.9030\n",
            "Epoch 13/100\n",
            "11015/11015 [==============================] - 2s 170us/step - loss: 1.6860 - acc: 0.8884 - f1_m: 0.9021\n",
            "Epoch 14/100\n",
            "11015/11015 [==============================] - 2s 172us/step - loss: 1.6847 - acc: 0.8881 - f1_m: 0.9020\n",
            "Epoch 15/100\n",
            "11015/11015 [==============================] - 2s 173us/step - loss: 1.7020 - acc: 0.8862 - f1_m: 0.9008\n",
            "Epoch 16/100\n",
            "11015/11015 [==============================] - 2s 169us/step - loss: 1.7136 - acc: 0.8872 - f1_m: 0.9006\n",
            "Epoch 17/100\n",
            "11015/11015 [==============================] - 2s 157us/step - loss: 1.6985 - acc: 0.8887 - f1_m: 0.9043\n",
            "Epoch 18/100\n",
            "11015/11015 [==============================] - 2s 166us/step - loss: 1.7211 - acc: 0.8851 - f1_m: 0.9029\n",
            "Epoch 19/100\n",
            "11015/11015 [==============================] - 2s 178us/step - loss: 1.5971 - acc: 0.8927 - f1_m: 0.9118\n",
            "Epoch 20/100\n",
            "11015/11015 [==============================] - 2s 159us/step - loss: 1.7181 - acc: 0.8864 - f1_m: 0.9033\n",
            "Epoch 21/100\n",
            "11015/11015 [==============================] - 2s 165us/step - loss: 1.7045 - acc: 0.8876 - f1_m: 0.9015\n",
            "Epoch 22/100\n",
            "11015/11015 [==============================] - 2s 165us/step - loss: 1.6768 - acc: 0.8909 - f1_m: 0.9039\n",
            "Epoch 23/100\n",
            "11015/11015 [==============================] - 2s 160us/step - loss: 1.6662 - acc: 0.8908 - f1_m: 0.9038\n",
            "Epoch 24/100\n",
            "11015/11015 [==============================] - 2s 161us/step - loss: 1.6740 - acc: 0.8901 - f1_m: 0.9035\n",
            "Epoch 25/100\n",
            "11015/11015 [==============================] - 2s 168us/step - loss: 1.6962 - acc: 0.8885 - f1_m: 0.9015\n",
            "Epoch 26/100\n",
            "11015/11015 [==============================] - 2s 168us/step - loss: 1.6969 - acc: 0.8882 - f1_m: 0.9008\n",
            "Epoch 27/100\n",
            "11015/11015 [==============================] - 2s 162us/step - loss: 1.6526 - acc: 0.8913 - f1_m: 0.9046\n",
            "Epoch 28/100\n",
            "11015/11015 [==============================] - 2s 173us/step - loss: 1.5445 - acc: 0.8977 - f1_m: 0.9132\n",
            "Epoch 29/100\n",
            "11015/11015 [==============================] - 2s 163us/step - loss: 1.6067 - acc: 0.8931 - f1_m: 0.9076\n",
            "Epoch 30/100\n",
            "11015/11015 [==============================] - 2s 155us/step - loss: 1.6681 - acc: 0.8903 - f1_m: 0.9034\n",
            "Epoch 31/100\n",
            "11015/11015 [==============================] - 2s 175us/step - loss: 1.6573 - acc: 0.8906 - f1_m: 0.9049\n",
            "Epoch 32/100\n",
            "11015/11015 [==============================] - 2s 156us/step - loss: 1.6616 - acc: 0.8895 - f1_m: 0.9046\n",
            "Epoch 33/100\n",
            "11015/11015 [==============================] - 2s 164us/step - loss: 1.7863 - acc: 0.8822 - f1_m: 0.9049\n",
            "Epoch 34/100\n",
            "11015/11015 [==============================] - 2s 183us/step - loss: 1.5805 - acc: 0.8958 - f1_m: 0.9105\n",
            "Epoch 35/100\n",
            "11015/11015 [==============================] - 2s 164us/step - loss: 1.6130 - acc: 0.8933 - f1_m: 0.9075\n",
            "Epoch 36/100\n",
            "11015/11015 [==============================] - 2s 160us/step - loss: 1.6214 - acc: 0.8923 - f1_m: 0.9064\n",
            "Epoch 37/100\n",
            "11015/11015 [==============================] - 2s 175us/step - loss: 1.6597 - acc: 0.8913 - f1_m: 0.9056\n",
            "Epoch 38/100\n",
            "11015/11015 [==============================] - 2s 170us/step - loss: 1.6690 - acc: 0.8908 - f1_m: 0.9043\n",
            "Epoch 39/100\n",
            "11015/11015 [==============================] - 2s 166us/step - loss: 1.6716 - acc: 0.8904 - f1_m: 0.9047\n",
            "Epoch 40/100\n",
            "11015/11015 [==============================] - 2s 159us/step - loss: 1.6781 - acc: 0.8890 - f1_m: 0.9022\n",
            "Epoch 41/100\n",
            "11015/11015 [==============================] - 2s 170us/step - loss: 1.7038 - acc: 0.8877 - f1_m: 0.9003\n",
            "Epoch 42/100\n",
            "11015/11015 [==============================] - 2s 160us/step - loss: 1.6637 - acc: 0.8911 - f1_m: 0.9041\n",
            "Epoch 43/100\n",
            "11015/11015 [==============================] - 2s 170us/step - loss: 1.6172 - acc: 0.8942 - f1_m: 0.9073\n",
            "Epoch 44/100\n",
            "11015/11015 [==============================] - 2s 176us/step - loss: 1.6062 - acc: 0.8954 - f1_m: 0.9087\n",
            "Epoch 45/100\n",
            "11015/11015 [==============================] - 2s 183us/step - loss: 1.6701 - acc: 0.8905 - f1_m: 0.9073\n",
            "Epoch 46/100\n",
            "11015/11015 [==============================] - 2s 175us/step - loss: 1.5961 - acc: 0.8951 - f1_m: 0.9111\n",
            "Epoch 47/100\n",
            "11015/11015 [==============================] - 2s 175us/step - loss: 1.5855 - acc: 0.8963 - f1_m: 0.9102\n",
            "Epoch 48/100\n",
            "11015/11015 [==============================] - 2s 165us/step - loss: 1.3960 - acc: 0.9081 - f1_m: 0.9228\n",
            "Epoch 49/100\n",
            "11015/11015 [==============================] - 2s 164us/step - loss: 1.4853 - acc: 0.9025 - f1_m: 0.9176\n",
            "Epoch 50/100\n",
            "11015/11015 [==============================] - 2s 176us/step - loss: 1.6108 - acc: 0.8942 - f1_m: 0.9070\n",
            "Epoch 51/100\n",
            "11015/11015 [==============================] - 2s 158us/step - loss: 1.6406 - acc: 0.8920 - f1_m: 0.9059\n",
            "Epoch 52/100\n",
            "11015/11015 [==============================] - 2s 160us/step - loss: 1.6256 - acc: 0.8928 - f1_m: 0.9060\n",
            "Epoch 53/100\n",
            "11015/11015 [==============================] - 2s 169us/step - loss: 1.6382 - acc: 0.8930 - f1_m: 0.9064\n",
            "Epoch 54/100\n",
            "11015/11015 [==============================] - 2s 155us/step - loss: 1.5932 - acc: 0.8969 - f1_m: 0.9107\n",
            "Epoch 55/100\n",
            "11015/11015 [==============================] - 2s 175us/step - loss: 1.6209 - acc: 0.8944 - f1_m: 0.9090\n",
            "Epoch 56/100\n",
            "11015/11015 [==============================] - 2s 169us/step - loss: 1.6268 - acc: 0.8942 - f1_m: 0.9075\n",
            "Epoch 57/100\n",
            "11015/11015 [==============================] - 2s 164us/step - loss: 1.6312 - acc: 0.8940 - f1_m: 0.9062\n",
            "Epoch 58/100\n",
            "11015/11015 [==============================] - 2s 176us/step - loss: 1.5902 - acc: 0.8970 - f1_m: 0.9097\n",
            "Epoch 59/100\n",
            "11015/11015 [==============================] - 2s 157us/step - loss: 1.5953 - acc: 0.8961 - f1_m: 0.9111\n",
            "Epoch 60/100\n",
            "11015/11015 [==============================] - 2s 158us/step - loss: 1.6137 - acc: 0.8946 - f1_m: 0.9074\n",
            "Epoch 61/100\n",
            "11015/11015 [==============================] - 2s 164us/step - loss: 1.6229 - acc: 0.8923 - f1_m: 0.9060\n",
            "Epoch 62/100\n",
            "11015/11015 [==============================] - 2s 163us/step - loss: 1.7842 - acc: 0.8830 - f1_m: 0.8996\n",
            "Epoch 63/100\n",
            "11015/11015 [==============================] - 2s 152us/step - loss: 1.6625 - acc: 0.8918 - f1_m: 0.9052\n",
            "Epoch 64/100\n",
            "11015/11015 [==============================] - 2s 153us/step - loss: 1.6093 - acc: 0.8940 - f1_m: 0.9091\n",
            "Epoch 65/100\n",
            "11015/11015 [==============================] - 2s 184us/step - loss: 1.5582 - acc: 0.8966 - f1_m: 0.9109\n",
            "Epoch 66/100\n",
            "11015/11015 [==============================] - 2s 169us/step - loss: 1.6643 - acc: 0.8926 - f1_m: 0.9059\n",
            "Epoch 67/100\n",
            "11015/11015 [==============================] - 2s 166us/step - loss: 1.6533 - acc: 0.8938 - f1_m: 0.9062\n",
            "Epoch 68/100\n",
            "11015/11015 [==============================] - 2s 165us/step - loss: 1.6474 - acc: 0.8944 - f1_m: 0.9075\n",
            "Epoch 69/100\n",
            "11015/11015 [==============================] - 2s 175us/step - loss: 1.6360 - acc: 0.8947 - f1_m: 0.9072\n",
            "Epoch 70/100\n",
            "11015/11015 [==============================] - 2s 167us/step - loss: 1.8318 - acc: 0.8807 - f1_m: 0.8994\n",
            "Epoch 71/100\n",
            "11015/11015 [==============================] - 2s 173us/step - loss: 1.6913 - acc: 0.8899 - f1_m: 0.9052\n",
            "Epoch 72/100\n",
            "11015/11015 [==============================] - 2s 159us/step - loss: 1.6425 - acc: 0.8938 - f1_m: 0.9071\n",
            "Epoch 73/100\n",
            "11015/11015 [==============================] - 2s 168us/step - loss: 1.6212 - acc: 0.8960 - f1_m: 0.9083\n",
            "Epoch 74/100\n",
            "11015/11015 [==============================] - 2s 153us/step - loss: 1.5247 - acc: 0.9017 - f1_m: 0.9149\n",
            "Epoch 75/100\n",
            "11015/11015 [==============================] - 2s 188us/step - loss: 1.7013 - acc: 0.8905 - f1_m: 0.9098\n",
            "Epoch 76/100\n",
            "11015/11015 [==============================] - 2s 183us/step - loss: 1.5362 - acc: 0.9008 - f1_m: 0.9151\n",
            "Epoch 77/100\n",
            "11015/11015 [==============================] - 2s 169us/step - loss: 1.3638 - acc: 0.9096 - f1_m: 0.9261\n",
            "Epoch 78/100\n",
            "11015/11015 [==============================] - 2s 169us/step - loss: 1.3740 - acc: 0.9077 - f1_m: 0.9230\n",
            "Epoch 79/100\n",
            "11015/11015 [==============================] - 2s 175us/step - loss: 1.4190 - acc: 0.9034 - f1_m: 0.9180\n",
            "Epoch 80/100\n",
            "11015/11015 [==============================] - 2s 165us/step - loss: 1.2608 - acc: 0.9130 - f1_m: 0.9273\n",
            "Epoch 81/100\n",
            "11015/11015 [==============================] - 2s 189us/step - loss: 1.2798 - acc: 0.9114 - f1_m: 0.9257\n",
            "Epoch 82/100\n",
            "11015/11015 [==============================] - 2s 169us/step - loss: 1.3037 - acc: 0.9098 - f1_m: 0.9237\n",
            "Epoch 83/100\n",
            "11015/11015 [==============================] - 2s 152us/step - loss: 1.2823 - acc: 0.9089 - f1_m: 0.9254\n",
            "Epoch 84/100\n",
            "11015/11015 [==============================] - 2s 172us/step - loss: 1.1749 - acc: 0.9160 - f1_m: 0.9305\n",
            "Epoch 85/100\n",
            "11015/11015 [==============================] - 2s 157us/step - loss: 1.2017 - acc: 0.9138 - f1_m: 0.9276\n",
            "Epoch 86/100\n",
            "11015/11015 [==============================] - 2s 175us/step - loss: 1.0334 - acc: 0.9131 - f1_m: 0.9277\n",
            "Epoch 87/100\n",
            "11015/11015 [==============================] - 2s 174us/step - loss: 0.9023 - acc: 0.8960 - f1_m: 0.9163\n",
            "Epoch 88/100\n",
            "11015/11015 [==============================] - 2s 154us/step - loss: 0.8511 - acc: 0.8949 - f1_m: 0.9156\n",
            "Epoch 89/100\n",
            "11015/11015 [==============================] - 2s 168us/step - loss: 0.7350 - acc: 0.8937 - f1_m: 0.9153\n",
            "Epoch 90/100\n",
            "11015/11015 [==============================] - 2s 165us/step - loss: 0.7339 - acc: 0.9060 - f1_m: 0.9247\n",
            "Epoch 91/100\n",
            "11015/11015 [==============================] - 2s 159us/step - loss: 0.7355 - acc: 0.8901 - f1_m: 0.9135\n",
            "Epoch 92/100\n",
            "11015/11015 [==============================] - 2s 173us/step - loss: 0.7395 - acc: 0.8847 - f1_m: 0.9088\n",
            "Epoch 93/100\n",
            "11015/11015 [==============================] - 2s 169us/step - loss: 0.7350 - acc: 0.8899 - f1_m: 0.9128\n",
            "Epoch 94/100\n",
            "11015/11015 [==============================] - 2s 165us/step - loss: 0.7285 - acc: 0.8969 - f1_m: 0.9177\n",
            "Epoch 95/100\n",
            "11015/11015 [==============================] - 2s 168us/step - loss: 0.7395 - acc: 0.8862 - f1_m: 0.9100\n",
            "Epoch 96/100\n",
            "11015/11015 [==============================] - 2s 178us/step - loss: 0.7698 - acc: 0.8910 - f1_m: 0.9140\n",
            "Epoch 97/100\n",
            "11015/11015 [==============================] - 2s 166us/step - loss: 0.7382 - acc: 0.8986 - f1_m: 0.9185\n",
            "Epoch 98/100\n",
            "11015/11015 [==============================] - 2s 171us/step - loss: 0.7616 - acc: 0.9021 - f1_m: 0.9212\n",
            "Epoch 99/100\n",
            "11015/11015 [==============================] - 2s 165us/step - loss: 0.7293 - acc: 0.8921 - f1_m: 0.9145\n",
            "Epoch 100/100\n",
            "11015/11015 [==============================] - 2s 160us/step - loss: 0.7391 - acc: 0.8961 - f1_m: 0.9175\n",
            "3672/3672 [==============================] - 1s 169us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4117: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_18 (InputLayer)        (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_59 (Dense)             (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_60 (Dense)             (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_61 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 1,601\n",
            "Trainable params: 1,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "11015/11015 [==============================] - 3s 277us/step - loss: 2.4152 - acc: 0.8332 - f1_m: 0.8583\n",
            "Epoch 2/100\n",
            "11015/11015 [==============================] - 2s 163us/step - loss: 2.3035 - acc: 0.8431 - f1_m: 0.8677\n",
            "Epoch 3/100\n",
            "11015/11015 [==============================] - 2s 158us/step - loss: 2.0148 - acc: 0.8630 - f1_m: 0.8897\n",
            "Epoch 4/100\n",
            "11015/11015 [==============================] - 2s 170us/step - loss: 1.6682 - acc: 0.8861 - f1_m: 0.9019\n",
            "Epoch 5/100\n",
            "11015/11015 [==============================] - 2s 175us/step - loss: 2.0969 - acc: 0.8586 - f1_m: 0.8886\n",
            "Epoch 6/100\n",
            "11015/11015 [==============================] - 2s 162us/step - loss: 1.7300 - acc: 0.8826 - f1_m: 0.8972\n",
            "Epoch 7/100\n",
            "11015/11015 [==============================] - 2s 186us/step - loss: 1.7806 - acc: 0.8806 - f1_m: 0.8946\n",
            "Epoch 8/100\n",
            "11015/11015 [==============================] - 2s 153us/step - loss: 1.7536 - acc: 0.8821 - f1_m: 0.8962\n",
            "Epoch 9/100\n",
            "11015/11015 [==============================] - 2s 158us/step - loss: 1.7402 - acc: 0.8836 - f1_m: 0.8984\n",
            "Epoch 10/100\n",
            "11015/11015 [==============================] - 2s 170us/step - loss: 1.5842 - acc: 0.8933 - f1_m: 0.9125\n",
            "Epoch 11/100\n",
            "11015/11015 [==============================] - 2s 174us/step - loss: 1.5206 - acc: 0.8977 - f1_m: 0.9142\n",
            "Epoch 12/100\n",
            "11015/11015 [==============================] - 2s 164us/step - loss: 1.5866 - acc: 0.8941 - f1_m: 0.9104\n",
            "Epoch 13/100\n",
            "11015/11015 [==============================] - 2s 147us/step - loss: 1.7363 - acc: 0.8849 - f1_m: 0.8985\n",
            "Epoch 14/100\n",
            "11015/11015 [==============================] - 2s 166us/step - loss: 1.7384 - acc: 0.8854 - f1_m: 0.8983\n",
            "Epoch 15/100\n",
            "11015/11015 [==============================] - 2s 170us/step - loss: 2.1648 - acc: 0.8574 - f1_m: 0.8836\n",
            "Epoch 16/100\n",
            "11015/11015 [==============================] - 2s 170us/step - loss: 2.2909 - acc: 0.8498 - f1_m: 0.8783\n",
            "Epoch 17/100\n",
            "11015/11015 [==============================] - 2s 163us/step - loss: 2.2800 - acc: 0.8503 - f1_m: 0.8785\n",
            "Epoch 18/100\n",
            "11015/11015 [==============================] - 2s 164us/step - loss: 1.8472 - acc: 0.8796 - f1_m: 0.8960\n",
            "Epoch 19/100\n",
            "11015/11015 [==============================] - 2s 159us/step - loss: 1.7373 - acc: 0.8856 - f1_m: 0.8993\n",
            "Epoch 20/100\n",
            "11015/11015 [==============================] - 2s 167us/step - loss: 1.7229 - acc: 0.8870 - f1_m: 0.9011\n",
            "Epoch 21/100\n",
            "11015/11015 [==============================] - 2s 165us/step - loss: 1.6092 - acc: 0.8939 - f1_m: 0.9081\n",
            "Epoch 22/100\n",
            "11015/11015 [==============================] - 2s 179us/step - loss: 1.5939 - acc: 0.8951 - f1_m: 0.9110\n",
            "Epoch 23/100\n",
            "11015/11015 [==============================] - 2s 160us/step - loss: 1.7261 - acc: 0.8879 - f1_m: 0.9013\n",
            "Epoch 24/100\n",
            "11015/11015 [==============================] - 2s 169us/step - loss: 1.7296 - acc: 0.8871 - f1_m: 0.8989\n",
            "Epoch 25/100\n",
            "11015/11015 [==============================] - 2s 181us/step - loss: 1.7202 - acc: 0.8876 - f1_m: 0.9012\n",
            "Epoch 26/100\n",
            "11015/11015 [==============================] - 2s 160us/step - loss: 1.7212 - acc: 0.8883 - f1_m: 0.9021\n",
            "Epoch 27/100\n",
            "11015/11015 [==============================] - 2s 166us/step - loss: 1.7489 - acc: 0.8855 - f1_m: 0.8991\n",
            "Epoch 28/100\n",
            "11015/11015 [==============================] - 2s 162us/step - loss: 1.7207 - acc: 0.8876 - f1_m: 0.9005\n",
            "Epoch 29/100\n",
            "11015/11015 [==============================] - 2s 163us/step - loss: 1.7123 - acc: 0.8882 - f1_m: 0.9018\n",
            "Epoch 30/100\n",
            "11015/11015 [==============================] - 2s 162us/step - loss: 1.7748 - acc: 0.8838 - f1_m: 0.8971\n",
            "Epoch 31/100\n",
            "11015/11015 [==============================] - 2s 155us/step - loss: 1.7718 - acc: 0.8840 - f1_m: 0.8967\n",
            "Epoch 32/100\n",
            "11015/11015 [==============================] - 2s 162us/step - loss: 1.6577 - acc: 0.8908 - f1_m: 0.9046\n",
            "Epoch 33/100\n",
            "11015/11015 [==============================] - 2s 160us/step - loss: 1.7062 - acc: 0.8889 - f1_m: 0.9044\n",
            "Epoch 34/100\n",
            "11015/11015 [==============================] - 2s 163us/step - loss: 1.5964 - acc: 0.8950 - f1_m: 0.9092\n",
            "Epoch 35/100\n",
            "11015/11015 [==============================] - 2s 169us/step - loss: 1.6676 - acc: 0.8911 - f1_m: 0.9052\n",
            "Epoch 36/100\n",
            "11015/11015 [==============================] - 2s 163us/step - loss: 1.6422 - acc: 0.8921 - f1_m: 0.9059\n",
            "Epoch 37/100\n",
            "11015/11015 [==============================] - 2s 160us/step - loss: 1.4642 - acc: 0.9030 - f1_m: 0.9183\n",
            "Epoch 38/100\n",
            "11015/11015 [==============================] - 2s 152us/step - loss: 1.5143 - acc: 0.9007 - f1_m: 0.9150\n",
            "Epoch 39/100\n",
            "11015/11015 [==============================] - 2s 168us/step - loss: 1.5003 - acc: 0.9022 - f1_m: 0.9187\n",
            "Epoch 40/100\n",
            "11015/11015 [==============================] - 2s 152us/step - loss: 1.5570 - acc: 0.8990 - f1_m: 0.9118\n",
            "Epoch 41/100\n",
            "11015/11015 [==============================] - 2s 163us/step - loss: 1.7087 - acc: 0.8887 - f1_m: 0.9026\n",
            "Epoch 42/100\n",
            "11015/11015 [==============================] - 2s 148us/step - loss: 1.8471 - acc: 0.8796 - f1_m: 0.8991\n",
            "Epoch 43/100\n",
            "11015/11015 [==============================] - 2s 150us/step - loss: 1.7060 - acc: 0.8887 - f1_m: 0.9022\n",
            "Epoch 44/100\n",
            "11015/11015 [==============================] - 2s 159us/step - loss: 1.6952 - acc: 0.8904 - f1_m: 0.9026\n",
            "Epoch 45/100\n",
            "11015/11015 [==============================] - 2s 187us/step - loss: 1.6946 - acc: 0.8904 - f1_m: 0.9038\n",
            "Epoch 46/100\n",
            "11015/11015 [==============================] - 2s 169us/step - loss: 1.7012 - acc: 0.8898 - f1_m: 0.9037\n",
            "Epoch 47/100\n",
            "11015/11015 [==============================] - 2s 166us/step - loss: 1.6244 - acc: 0.8946 - f1_m: 0.9086\n",
            "Epoch 48/100\n",
            "11015/11015 [==============================] - 2s 166us/step - loss: 1.7382 - acc: 0.8872 - f1_m: 0.9009\n",
            "Epoch 49/100\n",
            "11015/11015 [==============================] - 2s 160us/step - loss: 1.7162 - acc: 0.8895 - f1_m: 0.9021\n",
            "Epoch 50/100\n",
            "11015/11015 [==============================] - 2s 158us/step - loss: 1.7110 - acc: 0.8886 - f1_m: 0.9017\n",
            "Epoch 51/100\n",
            "11015/11015 [==============================] - 2s 176us/step - loss: 1.7148 - acc: 0.8889 - f1_m: 0.9025\n",
            "Epoch 52/100\n",
            "11015/11015 [==============================] - 2s 154us/step - loss: 1.7122 - acc: 0.8890 - f1_m: 0.9029\n",
            "Epoch 53/100\n",
            "11015/11015 [==============================] - 2s 165us/step - loss: 1.7002 - acc: 0.8892 - f1_m: 0.9027\n",
            "Epoch 54/100\n",
            "11015/11015 [==============================] - 2s 168us/step - loss: 1.7069 - acc: 0.8889 - f1_m: 0.9022\n",
            "Epoch 55/100\n",
            "11015/11015 [==============================] - 2s 179us/step - loss: 1.7025 - acc: 0.8888 - f1_m: 0.9015\n",
            "Epoch 56/100\n",
            "11015/11015 [==============================] - 2s 175us/step - loss: 1.6958 - acc: 0.8892 - f1_m: 0.9024\n",
            "Epoch 57/100\n",
            "11015/11015 [==============================] - 2s 162us/step - loss: 1.6953 - acc: 0.8892 - f1_m: 0.9033\n",
            "Epoch 58/100\n",
            "11015/11015 [==============================] - 2s 168us/step - loss: 1.7052 - acc: 0.8897 - f1_m: 0.9032\n",
            "Epoch 59/100\n",
            "11015/11015 [==============================] - 2s 157us/step - loss: 1.6986 - acc: 0.8900 - f1_m: 0.9022\n",
            "Epoch 60/100\n",
            "11015/11015 [==============================] - 2s 170us/step - loss: 1.6895 - acc: 0.8906 - f1_m: 0.9036\n",
            "Epoch 61/100\n",
            "11015/11015 [==============================] - 2s 155us/step - loss: 1.6900 - acc: 0.8901 - f1_m: 0.9036\n",
            "Epoch 62/100\n",
            "11015/11015 [==============================] - 2s 164us/step - loss: 1.6852 - acc: 0.8907 - f1_m: 0.9035\n",
            "Epoch 63/100\n",
            "11015/11015 [==============================] - 2s 175us/step - loss: 1.6904 - acc: 0.8904 - f1_m: 0.9036\n",
            "Epoch 64/100\n",
            "11015/11015 [==============================] - 2s 155us/step - loss: 1.6864 - acc: 0.8905 - f1_m: 0.9036\n",
            "Epoch 65/100\n",
            "11015/11015 [==============================] - 2s 174us/step - loss: 1.6841 - acc: 0.8915 - f1_m: 0.9043\n",
            "Epoch 66/100\n",
            "11015/11015 [==============================] - 2s 166us/step - loss: 1.6970 - acc: 0.8902 - f1_m: 0.9029\n",
            "Epoch 67/100\n",
            "11015/11015 [==============================] - 2s 187us/step - loss: 1.7048 - acc: 0.8895 - f1_m: 0.9016\n",
            "Epoch 68/100\n",
            "11015/11015 [==============================] - 2s 170us/step - loss: 1.7097 - acc: 0.8901 - f1_m: 0.9030\n",
            "Epoch 69/100\n",
            "11015/11015 [==============================] - 2s 176us/step - loss: 1.7078 - acc: 0.8897 - f1_m: 0.9026\n",
            "Epoch 70/100\n",
            "11015/11015 [==============================] - 2s 181us/step - loss: 1.7001 - acc: 0.8902 - f1_m: 0.9031\n",
            "Epoch 71/100\n",
            "11015/11015 [==============================] - 2s 182us/step - loss: 1.5548 - acc: 0.8989 - f1_m: 0.9120\n",
            "Epoch 72/100\n",
            "11015/11015 [==============================] - 2s 155us/step - loss: 1.6905 - acc: 0.8903 - f1_m: 0.9035\n",
            "Epoch 73/100\n",
            "11015/11015 [==============================] - 2s 151us/step - loss: 1.6938 - acc: 0.8906 - f1_m: 0.9036\n",
            "Epoch 74/100\n",
            "11015/11015 [==============================] - 2s 175us/step - loss: 1.6905 - acc: 0.8901 - f1_m: 0.9034\n",
            "Epoch 75/100\n",
            "11015/11015 [==============================] - 2s 167us/step - loss: 1.6895 - acc: 0.8902 - f1_m: 0.9033\n",
            "Epoch 76/100\n",
            "11015/11015 [==============================] - 2s 183us/step - loss: 1.6838 - acc: 0.8908 - f1_m: 0.9045\n",
            "Epoch 77/100\n",
            "11015/11015 [==============================] - 2s 177us/step - loss: 1.6974 - acc: 0.8889 - f1_m: 0.9008\n",
            "Epoch 78/100\n",
            "11015/11015 [==============================] - 2s 160us/step - loss: 1.6926 - acc: 0.8905 - f1_m: 0.9033\n",
            "Epoch 79/100\n",
            "11015/11015 [==============================] - 2s 164us/step - loss: 1.6923 - acc: 0.8898 - f1_m: 0.9024\n",
            "Epoch 80/100\n",
            "11015/11015 [==============================] - 2s 158us/step - loss: 1.6894 - acc: 0.8904 - f1_m: 0.9033\n",
            "Epoch 81/100\n",
            "11015/11015 [==============================] - 2s 168us/step - loss: 1.6907 - acc: 0.8896 - f1_m: 0.9013\n",
            "Epoch 82/100\n",
            "11015/11015 [==============================] - 2s 165us/step - loss: 1.6941 - acc: 0.8898 - f1_m: 0.9022\n",
            "Epoch 83/100\n",
            "11015/11015 [==============================] - 2s 164us/step - loss: 1.6796 - acc: 0.8913 - f1_m: 0.9029\n",
            "Epoch 84/100\n",
            "11015/11015 [==============================] - 2s 169us/step - loss: 1.6883 - acc: 0.8901 - f1_m: 0.9037\n",
            "Epoch 85/100\n",
            "11015/11015 [==============================] - 2s 169us/step - loss: 1.6867 - acc: 0.8909 - f1_m: 0.9037\n",
            "Epoch 86/100\n",
            "11015/11015 [==============================] - 2s 169us/step - loss: 1.6845 - acc: 0.8905 - f1_m: 0.9033\n",
            "Epoch 87/100\n",
            "11015/11015 [==============================] - 2s 162us/step - loss: 1.6817 - acc: 0.8917 - f1_m: 0.9046\n",
            "Epoch 88/100\n",
            "11015/11015 [==============================] - 2s 166us/step - loss: 1.5865 - acc: 0.8960 - f1_m: 0.9095\n",
            "Epoch 89/100\n",
            "11015/11015 [==============================] - 2s 171us/step - loss: 1.6807 - acc: 0.8903 - f1_m: 0.9028\n",
            "Epoch 90/100\n",
            "11015/11015 [==============================] - 2s 174us/step - loss: 1.6324 - acc: 0.8921 - f1_m: 0.9063\n",
            "Epoch 91/100\n",
            "11015/11015 [==============================] - 2s 169us/step - loss: 1.4835 - acc: 0.9032 - f1_m: 0.9197\n",
            "Epoch 92/100\n",
            "11015/11015 [==============================] - 2s 156us/step - loss: 1.3117 - acc: 0.9120 - f1_m: 0.9269\n",
            "Epoch 93/100\n",
            "11015/11015 [==============================] - 2s 161us/step - loss: 1.2677 - acc: 0.9149 - f1_m: 0.9295\n",
            "Epoch 94/100\n",
            "11015/11015 [==============================] - 2s 157us/step - loss: 1.2093 - acc: 0.9197 - f1_m: 0.9329\n",
            "Epoch 95/100\n",
            "11015/11015 [==============================] - 2s 152us/step - loss: 1.1934 - acc: 0.9208 - f1_m: 0.9345\n",
            "Epoch 96/100\n",
            "11015/11015 [==============================] - 2s 174us/step - loss: 1.4016 - acc: 0.9073 - f1_m: 0.9200\n",
            "Epoch 97/100\n",
            "11015/11015 [==============================] - 2s 171us/step - loss: 1.6721 - acc: 0.8918 - f1_m: 0.9039\n",
            "Epoch 98/100\n",
            "11015/11015 [==============================] - 2s 157us/step - loss: 1.6642 - acc: 0.8921 - f1_m: 0.9054\n",
            "Epoch 99/100\n",
            "11015/11015 [==============================] - 2s 165us/step - loss: 1.2699 - acc: 0.9152 - f1_m: 0.9279\n",
            "Epoch 100/100\n",
            "11015/11015 [==============================] - 2s 165us/step - loss: 1.5085 - acc: 0.9015 - f1_m: 0.9141\n",
            "3672/3672 [==============================] - 1s 188us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4117: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_19 (InputLayer)        (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_62 (Dense)             (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_63 (Dense)             (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_64 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 1,601\n",
            "Trainable params: 1,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "11015/11015 [==============================] - 3s 272us/step - loss: 2.0871 - acc: 0.8444 - f1_m: 0.8596\n",
            "Epoch 2/100\n",
            "11015/11015 [==============================] - 2s 185us/step - loss: 1.7164 - acc: 0.8809 - f1_m: 0.8966\n",
            "Epoch 3/100\n",
            "11015/11015 [==============================] - 2s 151us/step - loss: 1.7185 - acc: 0.8785 - f1_m: 0.8938\n",
            "Epoch 4/100\n",
            "11015/11015 [==============================] - 2s 167us/step - loss: 1.6755 - acc: 0.8852 - f1_m: 0.8994\n",
            "Epoch 5/100\n",
            "11015/11015 [==============================] - 2s 175us/step - loss: 1.6984 - acc: 0.8845 - f1_m: 0.8995\n",
            "Epoch 6/100\n",
            "11015/11015 [==============================] - 2s 159us/step - loss: 1.7837 - acc: 0.8796 - f1_m: 0.8938\n",
            "Epoch 7/100\n",
            "11015/11015 [==============================] - 2s 166us/step - loss: 1.6600 - acc: 0.8880 - f1_m: 0.9023\n",
            "Epoch 8/100\n",
            "11015/11015 [==============================] - 2s 165us/step - loss: 1.6632 - acc: 0.8874 - f1_m: 0.9017\n",
            "Epoch 9/100\n",
            "11015/11015 [==============================] - 2s 162us/step - loss: 1.7284 - acc: 0.8823 - f1_m: 0.8964\n",
            "Epoch 10/100\n",
            "11015/11015 [==============================] - 2s 168us/step - loss: 1.7518 - acc: 0.8833 - f1_m: 0.8975\n",
            "Epoch 11/100\n",
            "11015/11015 [==============================] - 2s 165us/step - loss: 1.6835 - acc: 0.8896 - f1_m: 0.9029\n",
            "Epoch 12/100\n",
            "11015/11015 [==============================] - 2s 167us/step - loss: 1.6736 - acc: 0.8890 - f1_m: 0.9024\n",
            "Epoch 13/100\n",
            "11015/11015 [==============================] - 2s 167us/step - loss: 1.6803 - acc: 0.8876 - f1_m: 0.9018\n",
            "Epoch 14/100\n",
            "11015/11015 [==============================] - 2s 163us/step - loss: 1.6675 - acc: 0.8898 - f1_m: 0.9034\n",
            "Epoch 15/100\n",
            "11015/11015 [==============================] - 2s 183us/step - loss: 1.6640 - acc: 0.8900 - f1_m: 0.9039\n",
            "Epoch 16/100\n",
            "11015/11015 [==============================] - 2s 162us/step - loss: 1.6537 - acc: 0.8911 - f1_m: 0.9048\n",
            "Epoch 17/100\n",
            "11015/11015 [==============================] - 2s 163us/step - loss: 1.6898 - acc: 0.8881 - f1_m: 0.9020\n",
            "Epoch 18/100\n",
            "11015/11015 [==============================] - 2s 160us/step - loss: 1.6737 - acc: 0.8889 - f1_m: 0.9021\n",
            "Epoch 19/100\n",
            "11015/11015 [==============================] - 2s 166us/step - loss: 1.6754 - acc: 0.8890 - f1_m: 0.9031\n",
            "Epoch 20/100\n",
            "11015/11015 [==============================] - 2s 170us/step - loss: 1.6457 - acc: 0.8916 - f1_m: 0.9045\n",
            "Epoch 21/100\n",
            "11015/11015 [==============================] - 2s 179us/step - loss: 1.6576 - acc: 0.8913 - f1_m: 0.9045\n",
            "Epoch 22/100\n",
            "11015/11015 [==============================] - 2s 169us/step - loss: 1.7182 - acc: 0.8842 - f1_m: 0.8953\n",
            "Epoch 23/100\n",
            "11015/11015 [==============================] - 2s 155us/step - loss: 1.7073 - acc: 0.8888 - f1_m: 0.9027\n",
            "Epoch 24/100\n",
            "11015/11015 [==============================] - 2s 165us/step - loss: 1.6870 - acc: 0.8904 - f1_m: 0.9037\n",
            "Epoch 25/100\n",
            "11015/11015 [==============================] - 2s 175us/step - loss: 1.8131 - acc: 0.8810 - f1_m: 0.8986\n",
            "Epoch 26/100\n",
            "11015/11015 [==============================] - 2s 174us/step - loss: 1.6692 - acc: 0.8911 - f1_m: 0.9040\n",
            "Epoch 27/100\n",
            "11015/11015 [==============================] - 2s 175us/step - loss: 1.6624 - acc: 0.8911 - f1_m: 0.9047\n",
            "Epoch 28/100\n",
            "11015/11015 [==============================] - 2s 168us/step - loss: 1.9208 - acc: 0.8750 - f1_m: 0.8975\n",
            "Epoch 29/100\n",
            "11015/11015 [==============================] - 2s 157us/step - loss: 1.6536 - acc: 0.8910 - f1_m: 0.9049\n",
            "Epoch 30/100\n",
            "11015/11015 [==============================] - 2s 171us/step - loss: 1.6459 - acc: 0.8925 - f1_m: 0.9054\n",
            "Epoch 31/100\n",
            "11015/11015 [==============================] - 2s 174us/step - loss: 1.6423 - acc: 0.8920 - f1_m: 0.9053\n",
            "Epoch 32/100\n",
            "11015/11015 [==============================] - 2s 165us/step - loss: 1.6322 - acc: 0.8932 - f1_m: 0.9063\n",
            "Epoch 33/100\n",
            "11015/11015 [==============================] - 2s 151us/step - loss: 1.6453 - acc: 0.8918 - f1_m: 0.9056\n",
            "Epoch 34/100\n",
            "11015/11015 [==============================] - 2s 165us/step - loss: 1.6435 - acc: 0.8924 - f1_m: 0.9063\n",
            "Epoch 35/100\n",
            "11015/11015 [==============================] - 2s 177us/step - loss: 1.6697 - acc: 0.8902 - f1_m: 0.9059\n",
            "Epoch 36/100\n",
            "11015/11015 [==============================] - 2s 172us/step - loss: 1.7871 - acc: 0.8824 - f1_m: 0.9029\n",
            "Epoch 37/100\n",
            "11015/11015 [==============================] - 2s 166us/step - loss: 1.6693 - acc: 0.8883 - f1_m: 0.9030\n",
            "Epoch 38/100\n",
            "11015/11015 [==============================] - 2s 167us/step - loss: 1.5833 - acc: 0.8962 - f1_m: 0.9104\n",
            "Epoch 39/100\n",
            "11015/11015 [==============================] - 2s 163us/step - loss: 1.6254 - acc: 0.8933 - f1_m: 0.9069\n",
            "Epoch 40/100\n",
            "11015/11015 [==============================] - 2s 167us/step - loss: 1.5978 - acc: 0.8959 - f1_m: 0.9090\n",
            "Epoch 41/100\n",
            "11015/11015 [==============================] - 2s 191us/step - loss: 1.5963 - acc: 0.8954 - f1_m: 0.9084\n",
            "Epoch 42/100\n",
            "11015/11015 [==============================] - 2s 181us/step - loss: 1.6342 - acc: 0.8931 - f1_m: 0.9071\n",
            "Epoch 43/100\n",
            "11015/11015 [==============================] - 2s 169us/step - loss: 1.6600 - acc: 0.8892 - f1_m: 0.9022\n",
            "Epoch 44/100\n",
            "11015/11015 [==============================] - 2s 177us/step - loss: 1.6782 - acc: 0.8879 - f1_m: 0.9016\n",
            "Epoch 45/100\n",
            "11015/11015 [==============================] - 2s 172us/step - loss: 1.6321 - acc: 0.8918 - f1_m: 0.9053\n",
            "Epoch 46/100\n",
            "11015/11015 [==============================] - 2s 163us/step - loss: 1.6249 - acc: 0.8929 - f1_m: 0.9056\n",
            "Epoch 47/100\n",
            "11015/11015 [==============================] - 2s 172us/step - loss: 1.6271 - acc: 0.8927 - f1_m: 0.9056\n",
            "Epoch 48/100\n",
            "11015/11015 [==============================] - 2s 163us/step - loss: 1.6230 - acc: 0.8939 - f1_m: 0.9070\n",
            "Epoch 49/100\n",
            "11015/11015 [==============================] - 2s 166us/step - loss: 1.6669 - acc: 0.8876 - f1_m: 0.9018\n",
            "Epoch 50/100\n",
            "11015/11015 [==============================] - 2s 164us/step - loss: 1.6327 - acc: 0.8906 - f1_m: 0.9039\n",
            "Epoch 51/100\n",
            "11015/11015 [==============================] - 2s 163us/step - loss: 1.6300 - acc: 0.8910 - f1_m: 0.9035\n",
            "Epoch 52/100\n",
            "11015/11015 [==============================] - 2s 162us/step - loss: 1.6706 - acc: 0.8872 - f1_m: 0.9019\n",
            "Epoch 53/100\n",
            "11015/11015 [==============================] - 2s 154us/step - loss: 1.6271 - acc: 0.8914 - f1_m: 0.9052\n",
            "Epoch 54/100\n",
            "11015/11015 [==============================] - 2s 159us/step - loss: 1.6283 - acc: 0.8910 - f1_m: 0.9039\n",
            "Epoch 55/100\n",
            "11015/11015 [==============================] - 2s 167us/step - loss: 1.6456 - acc: 0.8905 - f1_m: 0.9040\n",
            "Epoch 56/100\n",
            "11015/11015 [==============================] - 2s 164us/step - loss: 1.6450 - acc: 0.8918 - f1_m: 0.9045\n",
            "Epoch 57/100\n",
            "11015/11015 [==============================] - 2s 165us/step - loss: 1.6251 - acc: 0.8911 - f1_m: 0.9046\n",
            "Epoch 58/100\n",
            "11015/11015 [==============================] - 2s 156us/step - loss: 1.6126 - acc: 0.8919 - f1_m: 0.9058\n",
            "Epoch 59/100\n",
            "11015/11015 [==============================] - 2s 160us/step - loss: 1.6199 - acc: 0.8924 - f1_m: 0.9053\n",
            "Epoch 60/100\n",
            "11015/11015 [==============================] - 2s 156us/step - loss: 1.6174 - acc: 0.8934 - f1_m: 0.9066\n",
            "Epoch 61/100\n",
            "11015/11015 [==============================] - 2s 167us/step - loss: 1.6101 - acc: 0.8941 - f1_m: 0.9073\n",
            "Epoch 62/100\n",
            "11015/11015 [==============================] - 2s 151us/step - loss: 1.6117 - acc: 0.8935 - f1_m: 0.9064\n",
            "Epoch 63/100\n",
            "11015/11015 [==============================] - 2s 152us/step - loss: 1.6445 - acc: 0.8916 - f1_m: 0.9045\n",
            "Epoch 64/100\n",
            "11015/11015 [==============================] - 2s 163us/step - loss: 1.6400 - acc: 0.8930 - f1_m: 0.9061\n",
            "Epoch 65/100\n",
            "11015/11015 [==============================] - 2s 175us/step - loss: 1.6107 - acc: 0.8951 - f1_m: 0.9077\n",
            "Epoch 66/100\n",
            "11015/11015 [==============================] - 2s 180us/step - loss: 1.6086 - acc: 0.8940 - f1_m: 0.9072\n",
            "Epoch 67/100\n",
            "11015/11015 [==============================] - 2s 168us/step - loss: 1.5810 - acc: 0.8944 - f1_m: 0.9067\n",
            "Epoch 68/100\n",
            "11015/11015 [==============================] - 2s 170us/step - loss: 1.4769 - acc: 0.8965 - f1_m: 0.9099\n",
            "Epoch 69/100\n",
            "11015/11015 [==============================] - 2s 178us/step - loss: 1.4724 - acc: 0.8923 - f1_m: 0.9046\n",
            "Epoch 70/100\n",
            "11015/11015 [==============================] - 2s 161us/step - loss: 1.4354 - acc: 0.8931 - f1_m: 0.9056\n",
            "Epoch 71/100\n",
            "11015/11015 [==============================] - 2s 167us/step - loss: 1.4344 - acc: 0.8908 - f1_m: 0.9028\n",
            "Epoch 72/100\n",
            "11015/11015 [==============================] - 2s 156us/step - loss: 1.4483 - acc: 0.8915 - f1_m: 0.9051\n",
            "Epoch 73/100\n",
            "11015/11015 [==============================] - 2s 168us/step - loss: 1.4352 - acc: 0.8919 - f1_m: 0.9046\n",
            "Epoch 74/100\n",
            "11015/11015 [==============================] - 2s 162us/step - loss: 1.4307 - acc: 0.8939 - f1_m: 0.9068\n",
            "Epoch 75/100\n",
            "11015/11015 [==============================] - 2s 179us/step - loss: 1.4383 - acc: 0.8913 - f1_m: 0.9045\n",
            "Epoch 76/100\n",
            "11015/11015 [==============================] - 2s 176us/step - loss: 1.4401 - acc: 0.8921 - f1_m: 0.9042\n",
            "Epoch 77/100\n",
            "11015/11015 [==============================] - 2s 171us/step - loss: 1.4320 - acc: 0.8932 - f1_m: 0.9067\n",
            "Epoch 78/100\n",
            "11015/11015 [==============================] - 2s 155us/step - loss: 1.4196 - acc: 0.8927 - f1_m: 0.9057\n",
            "Epoch 79/100\n",
            "11015/11015 [==============================] - 2s 175us/step - loss: 1.4122 - acc: 0.8931 - f1_m: 0.9058\n",
            "Epoch 80/100\n",
            "11015/11015 [==============================] - 2s 174us/step - loss: 1.4087 - acc: 0.8919 - f1_m: 0.9042\n",
            "Epoch 81/100\n",
            "11015/11015 [==============================] - 2s 158us/step - loss: 1.4119 - acc: 0.8907 - f1_m: 0.9023\n",
            "Epoch 82/100\n",
            "11015/11015 [==============================] - 2s 156us/step - loss: 1.4146 - acc: 0.8918 - f1_m: 0.9041\n",
            "Epoch 83/100\n",
            "11015/11015 [==============================] - 2s 163us/step - loss: 1.4140 - acc: 0.8925 - f1_m: 0.9055\n",
            "Epoch 84/100\n",
            "11015/11015 [==============================] - 2s 148us/step - loss: 1.4187 - acc: 0.8919 - f1_m: 0.9048\n",
            "Epoch 85/100\n",
            "11015/11015 [==============================] - 2s 162us/step - loss: 1.4337 - acc: 0.8892 - f1_m: 0.9016\n",
            "Epoch 86/100\n",
            "11015/11015 [==============================] - 2s 159us/step - loss: 1.4270 - acc: 0.8912 - f1_m: 0.9037\n",
            "Epoch 87/100\n",
            "11015/11015 [==============================] - 2s 160us/step - loss: 1.4318 - acc: 0.8898 - f1_m: 0.9016\n",
            "Epoch 88/100\n",
            "11015/11015 [==============================] - 2s 172us/step - loss: 1.4221 - acc: 0.8908 - f1_m: 0.9036\n",
            "Epoch 89/100\n",
            "11015/11015 [==============================] - 2s 150us/step - loss: 1.4030 - acc: 0.8918 - f1_m: 0.9049\n",
            "Epoch 90/100\n",
            "11015/11015 [==============================] - 2s 160us/step - loss: 1.3733 - acc: 0.8910 - f1_m: 0.9069\n",
            "Epoch 91/100\n",
            "11015/11015 [==============================] - 2s 154us/step - loss: 1.4000 - acc: 0.8902 - f1_m: 0.9026\n",
            "Epoch 92/100\n",
            "11015/11015 [==============================] - 2s 148us/step - loss: 1.3509 - acc: 0.8911 - f1_m: 0.9045\n",
            "Epoch 93/100\n",
            "11015/11015 [==============================] - 2s 162us/step - loss: 1.3218 - acc: 0.8926 - f1_m: 0.9052\n",
            "Epoch 94/100\n",
            "11015/11015 [==============================] - 2s 160us/step - loss: 1.3154 - acc: 0.8939 - f1_m: 0.9058\n",
            "Epoch 95/100\n",
            "11015/11015 [==============================] - 2s 164us/step - loss: 1.0988 - acc: 0.9014 - f1_m: 0.9143\n",
            "Epoch 96/100\n",
            "11015/11015 [==============================] - 2s 167us/step - loss: 0.7375 - acc: 0.9166 - f1_m: 0.9286\n",
            "Epoch 97/100\n",
            "11015/11015 [==============================] - 2s 162us/step - loss: 0.7395 - acc: 0.9176 - f1_m: 0.9293\n",
            "Epoch 98/100\n",
            "11015/11015 [==============================] - 2s 168us/step - loss: 0.7325 - acc: 0.9186 - f1_m: 0.9303\n",
            "Epoch 99/100\n",
            "11015/11015 [==============================] - 2s 169us/step - loss: 0.7331 - acc: 0.9169 - f1_m: 0.9291\n",
            "Epoch 100/100\n",
            "11015/11015 [==============================] - 2s 170us/step - loss: 0.7289 - acc: 0.9187 - f1_m: 0.9309\n",
            "3672/3672 [==============================] - 1s 185us/step\n",
            "(Loss, Accuracy, F1-score) after 5-fold cross validation [1.13987666 0.90343137 0.91886296]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAvMjENJAMc4",
        "colab_type": "text"
      },
      "source": [
        "# Deep neural network - Profile features + BERT sentence encoding\n",
        "\n",
        "In addition to the profile features, we also add the semantic information contained in user tweets. We use two parallel networks:\n",
        "\n",
        "1.   Network which takes BERT sentence encoding as its input\n",
        "2.   Network which takes profile features as its input\n",
        "\n",
        "The 1st network has a series of dense layers and an output of 32 dimensions (which captures the semantic information). The 2nd network takes the profile features. These outputs are concatenated and passed through a feed-forward network for classifying fake users.\n",
        "\n",
        "**Accuracy: 0.93801743, F1-score: 0.9483967**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC9ger6C5qDx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_bert_model(bert_dim=768, profile_dim=32):\n",
        "    '''\n",
        "        bert network\n",
        "    '''\n",
        "    bert_input = Input(shape=(bert_dim,))\n",
        "    bert_output = Dense(256, activation='relu')(bert_input)\n",
        "    bert_output = Dense(256, activation='relu')(bert_output)\n",
        "    bert_output = Dense(256, activation='relu')(bert_output)\n",
        "    bert_output = Dense(32, activation='relu')(bert_output)\n",
        "\n",
        "    '''\n",
        "        input for profile network\n",
        "    '''\n",
        "    profile_input = Input(shape=(profile_dim,))\n",
        "\n",
        "    '''\n",
        "        model for combined features\n",
        "    '''\n",
        "    x = concatenate([profile_input, bert_output])\n",
        "    output = Dense(32, activation='relu')(x)\n",
        "    output = Dense(16, activation='relu')(output)\n",
        "    output = Dense(1, activation='sigmoid')(output)\n",
        "\n",
        "    model = Model(inputs=[profile_input, bert_input], outputs=[output])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc', f1_m])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihunoKZr5tIq",
        "colab_type": "code",
        "outputId": "4e6c877a-e746-43f3-af5f-103db19fe90b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "cross_val_split = 5\n",
        "cross_val_metrics = []\n",
        "\n",
        "for i in range(cross_val_split):\n",
        "    '''\n",
        "        get data with bert embeddings\n",
        "    '''\n",
        "    train_x, train_y, test_x, test_y = get_dataset()\n",
        "\n",
        "    '''\n",
        "        build neural network model\n",
        "    '''\n",
        "    model = build_bert_model()\n",
        "    model.summary()\n",
        "\n",
        "    train_split = np.hsplit(train_x, np.array([32, 800]))[:2]\n",
        "    test_split = np.hsplit(test_x, np.array([32, 800]))[:2]\n",
        "    model.fit(x=train_split, y=train_y, batch_size=32, shuffle=True, epochs=100)\n",
        "\n",
        "    val_res = model.evaluate(test_split, test_y)\n",
        "    cross_val_metrics.append(np.array(val_res))\n",
        "\n",
        "print(\"(Loss, Accuracy, F1-score) after 5-fold cross validation\", np.sum(cross_val_metrics, axis=0)/cross_val_split)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4117: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            (None, 768)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_15 (Dense)                (None, 256)          196864      input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_16 (Dense)                (None, 256)          65792       dense_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_17 (Dense)                (None, 256)          65792       dense_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            (None, 32)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_18 (Dense)                (None, 32)           8224        dense_17[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 64)           0           input_6[0][0]                    \n",
            "                                                                 dense_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_19 (Dense)                (None, 32)           2080        concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_20 (Dense)                (None, 16)           528         dense_19[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_21 (Dense)                (None, 1)            17          dense_20[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 339,297\n",
            "Trainable params: 339,297\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "11015/11015 [==============================] - 3s 269us/step - loss: 1.9421 - acc: 0.8649 - f1_m: 0.8796\n",
            "Epoch 2/100\n",
            "11015/11015 [==============================] - 3s 243us/step - loss: 1.8173 - acc: 0.8746 - f1_m: 0.8912\n",
            "Epoch 3/100\n",
            "11015/11015 [==============================] - 3s 241us/step - loss: 1.7826 - acc: 0.8804 - f1_m: 0.8952\n",
            "Epoch 4/100\n",
            "11015/11015 [==============================] - 2s 215us/step - loss: 1.7681 - acc: 0.8838 - f1_m: 0.8970\n",
            "Epoch 5/100\n",
            "11015/11015 [==============================] - 2s 216us/step - loss: 1.7556 - acc: 0.8842 - f1_m: 0.8974\n",
            "Epoch 6/100\n",
            "11015/11015 [==============================] - 3s 244us/step - loss: 1.7190 - acc: 0.8884 - f1_m: 0.9014\n",
            "Epoch 7/100\n",
            "11015/11015 [==============================] - 2s 215us/step - loss: 1.7673 - acc: 0.8845 - f1_m: 0.8987\n",
            "Epoch 8/100\n",
            "11015/11015 [==============================] - 2s 220us/step - loss: 1.9725 - acc: 0.8714 - f1_m: 0.8908\n",
            "Epoch 9/100\n",
            "11015/11015 [==============================] - 2s 212us/step - loss: 1.7596 - acc: 0.8841 - f1_m: 0.9019\n",
            "Epoch 10/100\n",
            "11015/11015 [==============================] - 2s 220us/step - loss: 1.7307 - acc: 0.8860 - f1_m: 0.8996\n",
            "Epoch 11/100\n",
            "11015/11015 [==============================] - 3s 237us/step - loss: 1.7282 - acc: 0.8872 - f1_m: 0.9003\n",
            "Epoch 12/100\n",
            "11015/11015 [==============================] - 2s 221us/step - loss: 1.7306 - acc: 0.8874 - f1_m: 0.9010\n",
            "Epoch 13/100\n",
            "11015/11015 [==============================] - 2s 217us/step - loss: 1.7173 - acc: 0.8882 - f1_m: 0.9015\n",
            "Epoch 14/100\n",
            "11015/11015 [==============================] - 3s 252us/step - loss: 1.7342 - acc: 0.8862 - f1_m: 0.9000\n",
            "Epoch 15/100\n",
            "11015/11015 [==============================] - 2s 226us/step - loss: 1.7398 - acc: 0.8859 - f1_m: 0.8992\n",
            "Epoch 16/100\n",
            "11015/11015 [==============================] - 2s 218us/step - loss: 2.5486 - acc: 0.8333 - f1_m: 0.8671\n",
            "Epoch 17/100\n",
            "11015/11015 [==============================] - 3s 235us/step - loss: 2.5398 - acc: 0.8370 - f1_m: 0.8718\n",
            "Epoch 18/100\n",
            "11015/11015 [==============================] - 2s 227us/step - loss: 2.3240 - acc: 0.8516 - f1_m: 0.8810\n",
            "Epoch 19/100\n",
            "11015/11015 [==============================] - 2s 227us/step - loss: 2.2625 - acc: 0.8554 - f1_m: 0.8839\n",
            "Epoch 20/100\n",
            "11015/11015 [==============================] - 2s 221us/step - loss: 2.0652 - acc: 0.8675 - f1_m: 0.8921\n",
            "Epoch 21/100\n",
            "11015/11015 [==============================] - 2s 220us/step - loss: 2.2214 - acc: 0.8563 - f1_m: 0.8852\n",
            "Epoch 22/100\n",
            "11015/11015 [==============================] - 2s 215us/step - loss: 1.9197 - acc: 0.8747 - f1_m: 0.8950\n",
            "Epoch 23/100\n",
            "11015/11015 [==============================] - 2s 201us/step - loss: 1.8048 - acc: 0.8845 - f1_m: 0.8969\n",
            "Epoch 24/100\n",
            "11015/11015 [==============================] - 3s 233us/step - loss: 1.7843 - acc: 0.8862 - f1_m: 0.8982\n",
            "Epoch 25/100\n",
            "11015/11015 [==============================] - 3s 231us/step - loss: 1.7819 - acc: 0.8858 - f1_m: 0.8989\n",
            "Epoch 26/100\n",
            "11015/11015 [==============================] - 2s 227us/step - loss: 1.7429 - acc: 0.8891 - f1_m: 0.9018\n",
            "Epoch 27/100\n",
            "11015/11015 [==============================] - 3s 241us/step - loss: 1.7453 - acc: 0.8873 - f1_m: 0.9006\n",
            "Epoch 28/100\n",
            "11015/11015 [==============================] - 2s 213us/step - loss: 1.7040 - acc: 0.8882 - f1_m: 0.9008\n",
            "Epoch 29/100\n",
            "11015/11015 [==============================] - 2s 215us/step - loss: 1.6587 - acc: 0.8886 - f1_m: 0.9052\n",
            "Epoch 30/100\n",
            "11015/11015 [==============================] - 2s 222us/step - loss: 1.7244 - acc: 0.8865 - f1_m: 0.9003\n",
            "Epoch 31/100\n",
            "11015/11015 [==============================] - 2s 220us/step - loss: 1.7246 - acc: 0.8874 - f1_m: 0.9011\n",
            "Epoch 32/100\n",
            "11015/11015 [==============================] - 2s 225us/step - loss: 1.7192 - acc: 0.8892 - f1_m: 0.9027\n",
            "Epoch 33/100\n",
            "11015/11015 [==============================] - 2s 214us/step - loss: 1.7031 - acc: 0.8883 - f1_m: 0.9020\n",
            "Epoch 34/100\n",
            "11015/11015 [==============================] - 2s 214us/step - loss: 1.7153 - acc: 0.8882 - f1_m: 0.9019\n",
            "Epoch 35/100\n",
            "11015/11015 [==============================] - 2s 214us/step - loss: 1.7083 - acc: 0.8883 - f1_m: 0.9021\n",
            "Epoch 36/100\n",
            "11015/11015 [==============================] - 2s 208us/step - loss: 1.7304 - acc: 0.8835 - f1_m: 0.8979\n",
            "Epoch 37/100\n",
            "11015/11015 [==============================] - 3s 232us/step - loss: 1.7014 - acc: 0.8895 - f1_m: 0.9028\n",
            "Epoch 38/100\n",
            "11015/11015 [==============================] - 2s 221us/step - loss: 1.6922 - acc: 0.8881 - f1_m: 0.9020\n",
            "Epoch 39/100\n",
            "11015/11015 [==============================] - 2s 207us/step - loss: 1.6811 - acc: 0.8908 - f1_m: 0.9036\n",
            "Epoch 40/100\n",
            "11015/11015 [==============================] - 3s 234us/step - loss: 1.6809 - acc: 0.8898 - f1_m: 0.9034\n",
            "Epoch 41/100\n",
            "11015/11015 [==============================] - 3s 237us/step - loss: 1.6793 - acc: 0.8913 - f1_m: 0.9047\n",
            "Epoch 42/100\n",
            "11015/11015 [==============================] - 3s 229us/step - loss: 1.6798 - acc: 0.8917 - f1_m: 0.9051\n",
            "Epoch 43/100\n",
            "11015/11015 [==============================] - 2s 214us/step - loss: 1.6890 - acc: 0.8902 - f1_m: 0.9036\n",
            "Epoch 44/100\n",
            "11015/11015 [==============================] - 2s 214us/step - loss: 1.6583 - acc: 0.8868 - f1_m: 0.9008\n",
            "Epoch 45/100\n",
            "11015/11015 [==============================] - 3s 230us/step - loss: 1.7137 - acc: 0.8863 - f1_m: 0.8991\n",
            "Epoch 46/100\n",
            "11015/11015 [==============================] - 3s 237us/step - loss: 1.6911 - acc: 0.8909 - f1_m: 0.9041\n",
            "Epoch 47/100\n",
            "11015/11015 [==============================] - 2s 213us/step - loss: 1.6875 - acc: 0.8909 - f1_m: 0.9034\n",
            "Epoch 48/100\n",
            "11015/11015 [==============================] - 2s 226us/step - loss: 1.6885 - acc: 0.8910 - f1_m: 0.9048\n",
            "Epoch 49/100\n",
            "11015/11015 [==============================] - 2s 226us/step - loss: 1.6905 - acc: 0.8898 - f1_m: 0.9038\n",
            "Epoch 50/100\n",
            "11015/11015 [==============================] - 2s 222us/step - loss: 1.6842 - acc: 0.8912 - f1_m: 0.9046\n",
            "Epoch 51/100\n",
            "11015/11015 [==============================] - 2s 214us/step - loss: 1.6842 - acc: 0.8911 - f1_m: 0.9038\n",
            "Epoch 52/100\n",
            "11015/11015 [==============================] - 2s 222us/step - loss: 1.7038 - acc: 0.8882 - f1_m: 0.9016\n",
            "Epoch 53/100\n",
            "11015/11015 [==============================] - 3s 234us/step - loss: 1.6842 - acc: 0.8917 - f1_m: 0.9041\n",
            "Epoch 54/100\n",
            "11015/11015 [==============================] - 2s 213us/step - loss: 1.6805 - acc: 0.8911 - f1_m: 0.9043\n",
            "Epoch 55/100\n",
            "11015/11015 [==============================] - 3s 238us/step - loss: 1.7028 - acc: 0.8907 - f1_m: 0.9037\n",
            "Epoch 56/100\n",
            "11015/11015 [==============================] - 2s 220us/step - loss: 1.6886 - acc: 0.8876 - f1_m: 0.9001\n",
            "Epoch 57/100\n",
            "11015/11015 [==============================] - 2s 224us/step - loss: 1.6723 - acc: 0.8906 - f1_m: 0.9038\n",
            "Epoch 58/100\n",
            "11015/11015 [==============================] - 3s 230us/step - loss: 1.6680 - acc: 0.8927 - f1_m: 0.9059\n",
            "Epoch 59/100\n",
            "11015/11015 [==============================] - 2s 221us/step - loss: 1.6944 - acc: 0.8915 - f1_m: 0.9042\n",
            "Epoch 60/100\n",
            "11015/11015 [==============================] - 3s 233us/step - loss: 1.6730 - acc: 0.8928 - f1_m: 0.9060\n",
            "Epoch 61/100\n",
            "11015/11015 [==============================] - 2s 221us/step - loss: 1.6707 - acc: 0.8925 - f1_m: 0.9053\n",
            "Epoch 62/100\n",
            "11015/11015 [==============================] - 3s 246us/step - loss: 1.6326 - acc: 0.8936 - f1_m: 0.9095\n",
            "Epoch 63/100\n",
            "11015/11015 [==============================] - 3s 247us/step - loss: 1.7635 - acc: 0.8860 - f1_m: 0.9067\n",
            "Epoch 64/100\n",
            "11015/11015 [==============================] - 3s 232us/step - loss: 1.4333 - acc: 0.9059 - f1_m: 0.9204\n",
            "Epoch 65/100\n",
            "11015/11015 [==============================] - 2s 223us/step - loss: 1.5593 - acc: 0.8953 - f1_m: 0.9089\n",
            "Epoch 66/100\n",
            "11015/11015 [==============================] - 2s 203us/step - loss: 1.6681 - acc: 0.8911 - f1_m: 0.9046\n",
            "Epoch 67/100\n",
            "11015/11015 [==============================] - 3s 253us/step - loss: 1.6730 - acc: 0.8908 - f1_m: 0.9036\n",
            "Epoch 68/100\n",
            "11015/11015 [==============================] - 2s 222us/step - loss: 1.6534 - acc: 0.8932 - f1_m: 0.9058\n",
            "Epoch 69/100\n",
            "11015/11015 [==============================] - 2s 212us/step - loss: 1.6529 - acc: 0.8926 - f1_m: 0.9055\n",
            "Epoch 70/100\n",
            "11015/11015 [==============================] - 3s 232us/step - loss: 1.5673 - acc: 0.8973 - f1_m: 0.9115\n",
            "Epoch 71/100\n",
            "11015/11015 [==============================] - 3s 240us/step - loss: 1.3277 - acc: 0.9109 - f1_m: 0.9256\n",
            "Epoch 72/100\n",
            "11015/11015 [==============================] - 2s 214us/step - loss: 1.4885 - acc: 0.9027 - f1_m: 0.9150\n",
            "Epoch 73/100\n",
            "11015/11015 [==============================] - 2s 211us/step - loss: 1.5900 - acc: 0.8967 - f1_m: 0.9099\n",
            "Epoch 74/100\n",
            "11015/11015 [==============================] - 3s 232us/step - loss: 1.6547 - acc: 0.8926 - f1_m: 0.9055\n",
            "Epoch 75/100\n",
            "11015/11015 [==============================] - 3s 230us/step - loss: 1.6530 - acc: 0.8931 - f1_m: 0.9063\n",
            "Epoch 76/100\n",
            "11015/11015 [==============================] - 3s 233us/step - loss: 1.6586 - acc: 0.8920 - f1_m: 0.9050\n",
            "Epoch 77/100\n",
            "11015/11015 [==============================] - 2s 226us/step - loss: 1.6617 - acc: 0.8919 - f1_m: 0.9050\n",
            "Epoch 78/100\n",
            "11015/11015 [==============================] - 3s 227us/step - loss: 1.6462 - acc: 0.8921 - f1_m: 0.9050\n",
            "Epoch 79/100\n",
            "11015/11015 [==============================] - 3s 233us/step - loss: 1.6366 - acc: 0.8946 - f1_m: 0.9078\n",
            "Epoch 80/100\n",
            "11015/11015 [==============================] - 3s 230us/step - loss: 1.2920 - acc: 0.9127 - f1_m: 0.9273\n",
            "Epoch 81/100\n",
            "11015/11015 [==============================] - 3s 228us/step - loss: 1.2388 - acc: 0.9180 - f1_m: 0.9317\n",
            "Epoch 82/100\n",
            "11015/11015 [==============================] - 2s 219us/step - loss: 1.2548 - acc: 0.9152 - f1_m: 0.9292\n",
            "Epoch 83/100\n",
            "11015/11015 [==============================] - 2s 223us/step - loss: 1.4565 - acc: 0.9014 - f1_m: 0.9162\n",
            "Epoch 84/100\n",
            "11015/11015 [==============================] - 3s 236us/step - loss: 1.2349 - acc: 0.9158 - f1_m: 0.9301\n",
            "Epoch 85/100\n",
            "11015/11015 [==============================] - 2s 224us/step - loss: 1.2449 - acc: 0.9149 - f1_m: 0.9290\n",
            "Epoch 86/100\n",
            "11015/11015 [==============================] - 3s 231us/step - loss: 1.2480 - acc: 0.9156 - f1_m: 0.9328\n",
            "Epoch 87/100\n",
            "11015/11015 [==============================] - 3s 231us/step - loss: 1.4136 - acc: 0.9058 - f1_m: 0.9183\n",
            "Epoch 88/100\n",
            "11015/11015 [==============================] - 3s 228us/step - loss: 1.6603 - acc: 0.8909 - f1_m: 0.9037\n",
            "Epoch 89/100\n",
            "11015/11015 [==============================] - 3s 228us/step - loss: 1.6565 - acc: 0.8894 - f1_m: 0.9022\n",
            "Epoch 90/100\n",
            "11015/11015 [==============================] - 2s 223us/step - loss: 1.5461 - acc: 0.8944 - f1_m: 0.9076\n",
            "Epoch 91/100\n",
            "11015/11015 [==============================] - 2s 222us/step - loss: 1.4986 - acc: 0.8999 - f1_m: 0.9123\n",
            "Epoch 92/100\n",
            "11015/11015 [==============================] - 2s 205us/step - loss: 1.5152 - acc: 0.8991 - f1_m: 0.9133\n",
            "Epoch 93/100\n",
            "11015/11015 [==============================] - 2s 225us/step - loss: 1.3838 - acc: 0.9041 - f1_m: 0.9180\n",
            "Epoch 94/100\n",
            "11015/11015 [==============================] - 2s 225us/step - loss: 1.3275 - acc: 0.9046 - f1_m: 0.9187\n",
            "Epoch 95/100\n",
            "11015/11015 [==============================] - 2s 223us/step - loss: 1.2509 - acc: 0.9113 - f1_m: 0.9245\n",
            "Epoch 96/100\n",
            "11015/11015 [==============================] - 2s 218us/step - loss: 1.2160 - acc: 0.9167 - f1_m: 0.9283\n",
            "Epoch 97/100\n",
            "11015/11015 [==============================] - 2s 216us/step - loss: 0.7271 - acc: 0.9435 - f1_m: 0.9539\n",
            "Epoch 98/100\n",
            "11015/11015 [==============================] - 2s 200us/step - loss: 0.6242 - acc: 0.9501 - f1_m: 0.9588\n",
            "Epoch 99/100\n",
            "11015/11015 [==============================] - 2s 215us/step - loss: 0.6125 - acc: 0.9507 - f1_m: 0.9593\n",
            "Epoch 100/100\n",
            "11015/11015 [==============================] - 2s 215us/step - loss: 0.6368 - acc: 0.9493 - f1_m: 0.9582\n",
            "3672/3672 [==============================] - 0s 114us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4117: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            (None, 768)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_22 (Dense)                (None, 256)          196864      input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_23 (Dense)                (None, 256)          65792       dense_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_24 (Dense)                (None, 256)          65792       dense_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_8 (InputLayer)            (None, 32)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_25 (Dense)                (None, 32)           8224        dense_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 64)           0           input_8[0][0]                    \n",
            "                                                                 dense_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_26 (Dense)                (None, 32)           2080        concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_27 (Dense)                (None, 16)           528         dense_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_28 (Dense)                (None, 1)            17          dense_27[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 339,297\n",
            "Trainable params: 339,297\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "11015/11015 [==============================] - 3s 298us/step - loss: 2.4556 - acc: 0.8308 - f1_m: 0.8599\n",
            "Epoch 2/100\n",
            "11015/11015 [==============================] - 3s 227us/step - loss: 2.0624 - acc: 0.8575 - f1_m: 0.8784\n",
            "Epoch 3/100\n",
            "11015/11015 [==============================] - 3s 245us/step - loss: 1.9602 - acc: 0.8694 - f1_m: 0.8837\n",
            "Epoch 4/100\n",
            "11015/11015 [==============================] - 3s 236us/step - loss: 1.9318 - acc: 0.8722 - f1_m: 0.8862\n",
            "Epoch 5/100\n",
            "11015/11015 [==============================] - 3s 227us/step - loss: 1.9297 - acc: 0.8742 - f1_m: 0.8883\n",
            "Epoch 6/100\n",
            "11015/11015 [==============================] - 3s 254us/step - loss: 1.9334 - acc: 0.8739 - f1_m: 0.8865\n",
            "Epoch 7/100\n",
            "11015/11015 [==============================] - 3s 239us/step - loss: 1.9227 - acc: 0.8749 - f1_m: 0.8887\n",
            "Epoch 8/100\n",
            "11015/11015 [==============================] - 3s 227us/step - loss: 1.9182 - acc: 0.8749 - f1_m: 0.8885\n",
            "Epoch 9/100\n",
            "11015/11015 [==============================] - 3s 229us/step - loss: 1.9192 - acc: 0.8741 - f1_m: 0.8872\n",
            "Epoch 10/100\n",
            "11015/11015 [==============================] - 2s 222us/step - loss: 1.8004 - acc: 0.8820 - f1_m: 0.8959\n",
            "Epoch 11/100\n",
            "11015/11015 [==============================] - 2s 219us/step - loss: 1.6997 - acc: 0.8875 - f1_m: 0.9010\n",
            "Epoch 12/100\n",
            "11015/11015 [==============================] - 2s 212us/step - loss: 1.7164 - acc: 0.8876 - f1_m: 0.9002\n",
            "Epoch 13/100\n",
            "11015/11015 [==============================] - 3s 235us/step - loss: 1.6803 - acc: 0.8903 - f1_m: 0.9037\n",
            "Epoch 14/100\n",
            "11015/11015 [==============================] - 3s 237us/step - loss: 1.6911 - acc: 0.8892 - f1_m: 0.9018\n",
            "Epoch 15/100\n",
            "11015/11015 [==============================] - 3s 236us/step - loss: 1.6887 - acc: 0.8913 - f1_m: 0.9041\n",
            "Epoch 16/100\n",
            "11015/11015 [==============================] - 2s 225us/step - loss: 1.7033 - acc: 0.8889 - f1_m: 0.9018\n",
            "Epoch 17/100\n",
            "11015/11015 [==============================] - 2s 215us/step - loss: 1.6979 - acc: 0.8875 - f1_m: 0.9016\n",
            "Epoch 18/100\n",
            "11015/11015 [==============================] - 3s 229us/step - loss: 1.7188 - acc: 0.8836 - f1_m: 0.9003\n",
            "Epoch 19/100\n",
            "11015/11015 [==============================] - 3s 233us/step - loss: 1.6862 - acc: 0.8893 - f1_m: 0.9036\n",
            "Epoch 20/100\n",
            "11015/11015 [==============================] - 2s 218us/step - loss: 1.6570 - acc: 0.8925 - f1_m: 0.9060\n",
            "Epoch 21/100\n",
            "11015/11015 [==============================] - 3s 237us/step - loss: 1.6658 - acc: 0.8910 - f1_m: 0.9036\n",
            "Epoch 22/100\n",
            "11015/11015 [==============================] - 3s 247us/step - loss: 1.6624 - acc: 0.8925 - f1_m: 0.9054\n",
            "Epoch 23/100\n",
            "11015/11015 [==============================] - 2s 226us/step - loss: 1.6991 - acc: 0.8884 - f1_m: 0.9020\n",
            "Epoch 24/100\n",
            "11015/11015 [==============================] - 2s 215us/step - loss: 1.6555 - acc: 0.8914 - f1_m: 0.9047\n",
            "Epoch 25/100\n",
            "11015/11015 [==============================] - 2s 226us/step - loss: 1.5583 - acc: 0.8989 - f1_m: 0.9119\n",
            "Epoch 26/100\n",
            "11015/11015 [==============================] - 3s 232us/step - loss: 1.5992 - acc: 0.8953 - f1_m: 0.9082\n",
            "Epoch 27/100\n",
            "11015/11015 [==============================] - 3s 230us/step - loss: 1.8949 - acc: 0.8731 - f1_m: 0.8949\n",
            "Epoch 28/100\n",
            "11015/11015 [==============================] - 2s 227us/step - loss: 1.6931 - acc: 0.8893 - f1_m: 0.9033\n",
            "Epoch 29/100\n",
            "11015/11015 [==============================] - 3s 234us/step - loss: 1.7890 - acc: 0.8818 - f1_m: 0.9014\n",
            "Epoch 30/100\n",
            "11015/11015 [==============================] - 3s 229us/step - loss: 1.6706 - acc: 0.8908 - f1_m: 0.9040\n",
            "Epoch 31/100\n",
            "11015/11015 [==============================] - 2s 214us/step - loss: 1.6787 - acc: 0.8898 - f1_m: 0.9038\n",
            "Epoch 32/100\n",
            "11015/11015 [==============================] - 3s 243us/step - loss: 1.6851 - acc: 0.8884 - f1_m: 0.9027\n",
            "Epoch 33/100\n",
            "11015/11015 [==============================] - 3s 232us/step - loss: 1.6526 - acc: 0.8917 - f1_m: 0.9051\n",
            "Epoch 34/100\n",
            "11015/11015 [==============================] - 2s 216us/step - loss: 1.6447 - acc: 0.8920 - f1_m: 0.9053\n",
            "Epoch 35/100\n",
            "11015/11015 [==============================] - 3s 247us/step - loss: 1.6470 - acc: 0.8924 - f1_m: 0.9055\n",
            "Epoch 36/100\n",
            "11015/11015 [==============================] - 3s 230us/step - loss: 1.6441 - acc: 0.8916 - f1_m: 0.9048\n",
            "Epoch 37/100\n",
            "11015/11015 [==============================] - 2s 226us/step - loss: 1.6452 - acc: 0.8931 - f1_m: 0.9054\n",
            "Epoch 38/100\n",
            "11015/11015 [==============================] - 2s 215us/step - loss: 1.6514 - acc: 0.8906 - f1_m: 0.9023\n",
            "Epoch 39/100\n",
            "11015/11015 [==============================] - 3s 228us/step - loss: 1.6748 - acc: 0.8911 - f1_m: 0.9042\n",
            "Epoch 40/100\n",
            "11015/11015 [==============================] - 3s 229us/step - loss: 1.6358 - acc: 0.8916 - f1_m: 0.9061\n",
            "Epoch 41/100\n",
            "11015/11015 [==============================] - 2s 204us/step - loss: 1.5017 - acc: 0.8978 - f1_m: 0.9111\n",
            "Epoch 42/100\n",
            "11015/11015 [==============================] - 2s 221us/step - loss: 1.4906 - acc: 0.9006 - f1_m: 0.9136\n",
            "Epoch 43/100\n",
            "11015/11015 [==============================] - 3s 231us/step - loss: 1.5815 - acc: 0.8951 - f1_m: 0.9081\n",
            "Epoch 44/100\n",
            "11015/11015 [==============================] - 2s 217us/step - loss: 1.4864 - acc: 0.9010 - f1_m: 0.9139\n",
            "Epoch 45/100\n",
            "11015/11015 [==============================] - 2s 218us/step - loss: 1.4941 - acc: 0.9012 - f1_m: 0.9136\n",
            "Epoch 46/100\n",
            "11015/11015 [==============================] - 2s 220us/step - loss: 1.5212 - acc: 0.9000 - f1_m: 0.9136\n",
            "Epoch 47/100\n",
            "11015/11015 [==============================] - 2s 214us/step - loss: 1.5229 - acc: 0.8987 - f1_m: 0.9118\n",
            "Epoch 48/100\n",
            "11015/11015 [==============================] - 3s 236us/step - loss: 1.5014 - acc: 0.9008 - f1_m: 0.9140\n",
            "Epoch 49/100\n",
            "11015/11015 [==============================] - 3s 235us/step - loss: 1.5000 - acc: 0.8980 - f1_m: 0.9111\n",
            "Epoch 50/100\n",
            "11015/11015 [==============================] - 2s 208us/step - loss: 1.4943 - acc: 0.9004 - f1_m: 0.9130\n",
            "Epoch 51/100\n",
            "11015/11015 [==============================] - 3s 228us/step - loss: 1.4945 - acc: 0.8995 - f1_m: 0.9124\n",
            "Epoch 52/100\n",
            "11015/11015 [==============================] - 3s 233us/step - loss: 1.4763 - acc: 0.9020 - f1_m: 0.9145\n",
            "Epoch 53/100\n",
            "11015/11015 [==============================] - 3s 228us/step - loss: 1.4773 - acc: 0.9027 - f1_m: 0.9147\n",
            "Epoch 54/100\n",
            "11015/11015 [==============================] - 3s 234us/step - loss: 1.4783 - acc: 0.9029 - f1_m: 0.9150\n",
            "Epoch 55/100\n",
            "11015/11015 [==============================] - 3s 229us/step - loss: 1.4761 - acc: 0.9026 - f1_m: 0.9149\n",
            "Epoch 56/100\n",
            "11015/11015 [==============================] - 2s 223us/step - loss: 1.5152 - acc: 0.8999 - f1_m: 0.9120\n",
            "Epoch 57/100\n",
            "11015/11015 [==============================] - 3s 236us/step - loss: 1.4907 - acc: 0.8921 - f1_m: 0.9043\n",
            "Epoch 58/100\n",
            "11015/11015 [==============================] - 2s 223us/step - loss: 1.4866 - acc: 0.8932 - f1_m: 0.9063\n",
            "Epoch 59/100\n",
            "11015/11015 [==============================] - 2s 219us/step - loss: 1.4673 - acc: 0.8963 - f1_m: 0.9095\n",
            "Epoch 60/100\n",
            "11015/11015 [==============================] - 2s 225us/step - loss: 1.4710 - acc: 0.9012 - f1_m: 0.9139\n",
            "Epoch 61/100\n",
            "11015/11015 [==============================] - 2s 207us/step - loss: 1.3744 - acc: 0.8973 - f1_m: 0.9132\n",
            "Epoch 62/100\n",
            "11015/11015 [==============================] - 2s 205us/step - loss: 1.4779 - acc: 0.8946 - f1_m: 0.9117\n",
            "Epoch 63/100\n",
            "11015/11015 [==============================] - 3s 227us/step - loss: 1.1079 - acc: 0.8958 - f1_m: 0.9140\n",
            "Epoch 64/100\n",
            "11015/11015 [==============================] - 2s 226us/step - loss: 0.3497 - acc: 0.8791 - f1_m: 0.8983\n",
            "Epoch 65/100\n",
            "11015/11015 [==============================] - 3s 230us/step - loss: 0.3033 - acc: 0.8814 - f1_m: 0.8976\n",
            "Epoch 66/100\n",
            "11015/11015 [==============================] - 3s 232us/step - loss: 0.2719 - acc: 0.8883 - f1_m: 0.9047\n",
            "Epoch 67/100\n",
            "11015/11015 [==============================] - 3s 231us/step - loss: 0.2616 - acc: 0.8872 - f1_m: 0.9031\n",
            "Epoch 68/100\n",
            "11015/11015 [==============================] - 2s 222us/step - loss: 0.2387 - acc: 0.8889 - f1_m: 0.9055\n",
            "Epoch 69/100\n",
            "11015/11015 [==============================] - 2s 219us/step - loss: 0.2240 - acc: 0.8894 - f1_m: 0.9045\n",
            "Epoch 70/100\n",
            "11015/11015 [==============================] - 2s 217us/step - loss: 0.2200 - acc: 0.9004 - f1_m: 0.9161\n",
            "Epoch 71/100\n",
            "11015/11015 [==============================] - 3s 237us/step - loss: 0.1909 - acc: 0.9120 - f1_m: 0.9259\n",
            "Epoch 72/100\n",
            "11015/11015 [==============================] - 2s 211us/step - loss: 0.1791 - acc: 0.9180 - f1_m: 0.9318\n",
            "Epoch 73/100\n",
            "11015/11015 [==============================] - 3s 241us/step - loss: 0.1989 - acc: 0.9142 - f1_m: 0.9279\n",
            "Epoch 74/100\n",
            "11015/11015 [==============================] - 3s 228us/step - loss: 0.1911 - acc: 0.9135 - f1_m: 0.9276\n",
            "Epoch 75/100\n",
            "11015/11015 [==============================] - 3s 248us/step - loss: 0.1784 - acc: 0.9153 - f1_m: 0.9297\n",
            "Epoch 76/100\n",
            "11015/11015 [==============================] - 2s 226us/step - loss: 0.1739 - acc: 0.9257 - f1_m: 0.9386\n",
            "Epoch 77/100\n",
            "11015/11015 [==============================] - 3s 234us/step - loss: 0.1653 - acc: 0.9519 - f1_m: 0.9615\n",
            "Epoch 78/100\n",
            "11015/11015 [==============================] - 2s 217us/step - loss: 0.1636 - acc: 0.9516 - f1_m: 0.9615\n",
            "Epoch 79/100\n",
            "11015/11015 [==============================] - 3s 232us/step - loss: 0.1541 - acc: 0.9564 - f1_m: 0.9647\n",
            "Epoch 80/100\n",
            "11015/11015 [==============================] - 2s 208us/step - loss: 0.1473 - acc: 0.9601 - f1_m: 0.9678\n",
            "Epoch 81/100\n",
            "11015/11015 [==============================] - 3s 230us/step - loss: 0.1480 - acc: 0.9561 - f1_m: 0.9648\n",
            "Epoch 82/100\n",
            "11015/11015 [==============================] - 3s 231us/step - loss: 0.1453 - acc: 0.9536 - f1_m: 0.9628\n",
            "Epoch 83/100\n",
            "11015/11015 [==============================] - 3s 231us/step - loss: 0.1458 - acc: 0.9544 - f1_m: 0.9633\n",
            "Epoch 84/100\n",
            "11015/11015 [==============================] - 2s 221us/step - loss: 0.1441 - acc: 0.9561 - f1_m: 0.9644\n",
            "Epoch 85/100\n",
            "11015/11015 [==============================] - 2s 224us/step - loss: 0.1476 - acc: 0.9563 - f1_m: 0.9648\n",
            "Epoch 86/100\n",
            "11015/11015 [==============================] - 2s 220us/step - loss: 0.1626 - acc: 0.9499 - f1_m: 0.9596\n",
            "Epoch 87/100\n",
            "11015/11015 [==============================] - 2s 211us/step - loss: 0.1378 - acc: 0.9605 - f1_m: 0.9678\n",
            "Epoch 88/100\n",
            "11015/11015 [==============================] - 2s 217us/step - loss: 0.1332 - acc: 0.9616 - f1_m: 0.9689\n",
            "Epoch 89/100\n",
            "11015/11015 [==============================] - 3s 230us/step - loss: 0.1339 - acc: 0.9606 - f1_m: 0.9685\n",
            "Epoch 90/100\n",
            "11015/11015 [==============================] - 3s 230us/step - loss: 0.1336 - acc: 0.9599 - f1_m: 0.9678\n",
            "Epoch 91/100\n",
            "11015/11015 [==============================] - 2s 218us/step - loss: 0.1374 - acc: 0.9617 - f1_m: 0.9693\n",
            "Epoch 92/100\n",
            "11015/11015 [==============================] - 2s 208us/step - loss: 0.1462 - acc: 0.9583 - f1_m: 0.9666\n",
            "Epoch 93/100\n",
            "11015/11015 [==============================] - 2s 204us/step - loss: 0.1524 - acc: 0.9510 - f1_m: 0.9610\n",
            "Epoch 94/100\n",
            "11015/11015 [==============================] - 2s 224us/step - loss: 0.1459 - acc: 0.9577 - f1_m: 0.9660\n",
            "Epoch 95/100\n",
            "11015/11015 [==============================] - 2s 216us/step - loss: 0.1355 - acc: 0.9611 - f1_m: 0.9688\n",
            "Epoch 96/100\n",
            "11015/11015 [==============================] - 3s 243us/step - loss: 0.1249 - acc: 0.9647 - f1_m: 0.9714\n",
            "Epoch 97/100\n",
            "11015/11015 [==============================] - 2s 220us/step - loss: 0.1218 - acc: 0.9647 - f1_m: 0.9718\n",
            "Epoch 98/100\n",
            "11015/11015 [==============================] - 2s 220us/step - loss: 0.1202 - acc: 0.9679 - f1_m: 0.9740\n",
            "Epoch 99/100\n",
            "11015/11015 [==============================] - 2s 204us/step - loss: 0.1234 - acc: 0.9658 - f1_m: 0.9721\n",
            "Epoch 100/100\n",
            "11015/11015 [==============================] - 3s 238us/step - loss: 0.1198 - acc: 0.9683 - f1_m: 0.9736\n",
            "3672/3672 [==============================] - 0s 124us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4117: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_9 (InputLayer)            (None, 768)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_29 (Dense)                (None, 256)          196864      input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_30 (Dense)                (None, 256)          65792       dense_29[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_31 (Dense)                (None, 256)          65792       dense_30[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_10 (InputLayer)           (None, 32)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_32 (Dense)                (None, 32)           8224        dense_31[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 64)           0           input_10[0][0]                   \n",
            "                                                                 dense_32[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_33 (Dense)                (None, 32)           2080        concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_34 (Dense)                (None, 16)           528         dense_33[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_35 (Dense)                (None, 1)            17          dense_34[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 339,297\n",
            "Trainable params: 339,297\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "11015/11015 [==============================] - 3s 287us/step - loss: 2.1804 - acc: 0.8494 - f1_m: 0.8844\n",
            "Epoch 2/100\n",
            "11015/11015 [==============================] - 2s 206us/step - loss: 1.8950 - acc: 0.8692 - f1_m: 0.8982\n",
            "Epoch 3/100\n",
            "11015/11015 [==============================] - 3s 231us/step - loss: 2.0967 - acc: 0.8552 - f1_m: 0.8886\n",
            "Epoch 4/100\n",
            "11015/11015 [==============================] - 2s 218us/step - loss: 1.7388 - acc: 0.8790 - f1_m: 0.8933\n",
            "Epoch 5/100\n",
            "11015/11015 [==============================] - 2s 225us/step - loss: 1.5478 - acc: 0.8927 - f1_m: 0.9091\n",
            "Epoch 6/100\n",
            "11015/11015 [==============================] - 2s 220us/step - loss: 1.3728 - acc: 0.9020 - f1_m: 0.9188\n",
            "Epoch 7/100\n",
            "11015/11015 [==============================] - 3s 236us/step - loss: 1.8380 - acc: 0.8777 - f1_m: 0.8950\n",
            "Epoch 8/100\n",
            "11015/11015 [==============================] - 2s 225us/step - loss: 1.8595 - acc: 0.8775 - f1_m: 0.8920\n",
            "Epoch 9/100\n",
            "11015/11015 [==============================] - 3s 240us/step - loss: 1.7843 - acc: 0.8812 - f1_m: 0.8955\n",
            "Epoch 10/100\n",
            "11015/11015 [==============================] - 3s 243us/step - loss: 1.7710 - acc: 0.8841 - f1_m: 0.8980\n",
            "Epoch 11/100\n",
            "11015/11015 [==============================] - 3s 233us/step - loss: 1.7217 - acc: 0.8842 - f1_m: 0.8980\n",
            "Epoch 12/100\n",
            "11015/11015 [==============================] - 3s 228us/step - loss: 1.7089 - acc: 0.8856 - f1_m: 0.8996\n",
            "Epoch 13/100\n",
            "11015/11015 [==============================] - 2s 222us/step - loss: 1.7519 - acc: 0.8828 - f1_m: 0.8977\n",
            "Epoch 14/100\n",
            "11015/11015 [==============================] - 2s 212us/step - loss: 1.7404 - acc: 0.8854 - f1_m: 0.8996\n",
            "Epoch 15/100\n",
            "11015/11015 [==============================] - 3s 234us/step - loss: 1.6942 - acc: 0.8872 - f1_m: 0.9001\n",
            "Epoch 16/100\n",
            "11015/11015 [==============================] - 2s 219us/step - loss: 1.6910 - acc: 0.8882 - f1_m: 0.9011\n",
            "Epoch 17/100\n",
            "11015/11015 [==============================] - 3s 229us/step - loss: 1.6734 - acc: 0.8901 - f1_m: 0.9035\n",
            "Epoch 18/100\n",
            "11015/11015 [==============================] - 3s 242us/step - loss: 1.6184 - acc: 0.8915 - f1_m: 0.9054\n",
            "Epoch 19/100\n",
            "11015/11015 [==============================] - 2s 225us/step - loss: 1.5689 - acc: 0.8956 - f1_m: 0.9123\n",
            "Epoch 20/100\n",
            "11015/11015 [==============================] - 2s 217us/step - loss: 1.7872 - acc: 0.8825 - f1_m: 0.8977\n",
            "Epoch 21/100\n",
            "11015/11015 [==============================] - 2s 223us/step - loss: 1.6858 - acc: 0.8893 - f1_m: 0.9024\n",
            "Epoch 22/100\n",
            "11015/11015 [==============================] - 2s 218us/step - loss: 1.6791 - acc: 0.8892 - f1_m: 0.9020\n",
            "Epoch 23/100\n",
            "11015/11015 [==============================] - 3s 228us/step - loss: 1.6226 - acc: 0.8924 - f1_m: 0.9073\n",
            "Epoch 24/100\n",
            "11015/11015 [==============================] - 2s 217us/step - loss: 1.7091 - acc: 0.8882 - f1_m: 0.9019\n",
            "Epoch 25/100\n",
            "11015/11015 [==============================] - 3s 237us/step - loss: 1.6810 - acc: 0.8908 - f1_m: 0.9037\n",
            "Epoch 26/100\n",
            "11015/11015 [==============================] - 3s 247us/step - loss: 1.6846 - acc: 0.8901 - f1_m: 0.9033\n",
            "Epoch 27/100\n",
            "11015/11015 [==============================] - 3s 231us/step - loss: 1.6817 - acc: 0.8901 - f1_m: 0.9031\n",
            "Epoch 28/100\n",
            "11015/11015 [==============================] - 2s 225us/step - loss: 1.6667 - acc: 0.8904 - f1_m: 0.9033\n",
            "Epoch 29/100\n",
            "11015/11015 [==============================] - 3s 249us/step - loss: 1.6687 - acc: 0.8913 - f1_m: 0.9040\n",
            "Epoch 30/100\n",
            "11015/11015 [==============================] - 3s 246us/step - loss: 1.6949 - acc: 0.8896 - f1_m: 0.9023\n",
            "Epoch 31/100\n",
            "11015/11015 [==============================] - 2s 222us/step - loss: 1.7104 - acc: 0.8892 - f1_m: 0.9021\n",
            "Epoch 32/100\n",
            "11015/11015 [==============================] - 3s 232us/step - loss: 1.6924 - acc: 0.8899 - f1_m: 0.9028\n",
            "Epoch 33/100\n",
            "11015/11015 [==============================] - 3s 245us/step - loss: 1.6690 - acc: 0.8910 - f1_m: 0.9042\n",
            "Epoch 34/100\n",
            "11015/11015 [==============================] - 3s 240us/step - loss: 1.6711 - acc: 0.8915 - f1_m: 0.9039\n",
            "Epoch 35/100\n",
            "11015/11015 [==============================] - 3s 241us/step - loss: 1.6679 - acc: 0.8918 - f1_m: 0.9042\n",
            "Epoch 36/100\n",
            "11015/11015 [==============================] - 3s 239us/step - loss: 1.6806 - acc: 0.8886 - f1_m: 0.9028\n",
            "Epoch 37/100\n",
            "11015/11015 [==============================] - 2s 223us/step - loss: 1.6424 - acc: 0.8931 - f1_m: 0.9064\n",
            "Epoch 38/100\n",
            "11015/11015 [==============================] - 2s 221us/step - loss: 1.6546 - acc: 0.8929 - f1_m: 0.9058\n",
            "Epoch 39/100\n",
            "11015/11015 [==============================] - 2s 225us/step - loss: 1.6490 - acc: 0.8921 - f1_m: 0.9046\n",
            "Epoch 40/100\n",
            "11015/11015 [==============================] - 3s 244us/step - loss: 1.6631 - acc: 0.8904 - f1_m: 0.9026\n",
            "Epoch 41/100\n",
            "11015/11015 [==============================] - 2s 222us/step - loss: 1.6504 - acc: 0.8922 - f1_m: 0.9051\n",
            "Epoch 42/100\n",
            "11015/11015 [==============================] - 3s 236us/step - loss: 1.6454 - acc: 0.8933 - f1_m: 0.9062\n",
            "Epoch 43/100\n",
            "11015/11015 [==============================] - 2s 212us/step - loss: 1.6481 - acc: 0.8921 - f1_m: 0.9048\n",
            "Epoch 44/100\n",
            "11015/11015 [==============================] - 3s 244us/step - loss: 1.6609 - acc: 0.8911 - f1_m: 0.9043\n",
            "Epoch 45/100\n",
            "11015/11015 [==============================] - 3s 228us/step - loss: 1.6428 - acc: 0.8939 - f1_m: 0.9065\n",
            "Epoch 46/100\n",
            "11015/11015 [==============================] - 3s 233us/step - loss: 1.6467 - acc: 0.8927 - f1_m: 0.9064\n",
            "Epoch 47/100\n",
            "11015/11015 [==============================] - 3s 247us/step - loss: 1.6767 - acc: 0.8920 - f1_m: 0.9049\n",
            "Epoch 48/100\n",
            "11015/11015 [==============================] - 3s 227us/step - loss: 1.6683 - acc: 0.8922 - f1_m: 0.9047\n",
            "Epoch 49/100\n",
            "11015/11015 [==============================] - 2s 210us/step - loss: 1.6772 - acc: 0.8916 - f1_m: 0.9045\n",
            "Epoch 50/100\n",
            "11015/11015 [==============================] - 2s 221us/step - loss: 1.6481 - acc: 0.8935 - f1_m: 0.9059\n",
            "Epoch 51/100\n",
            "11015/11015 [==============================] - 3s 263us/step - loss: 1.6617 - acc: 0.8921 - f1_m: 0.9042\n",
            "Epoch 52/100\n",
            "11015/11015 [==============================] - 2s 219us/step - loss: 1.6571 - acc: 0.8931 - f1_m: 0.9063\n",
            "Epoch 53/100\n",
            "11015/11015 [==============================] - 2s 227us/step - loss: 1.6911 - acc: 0.8894 - f1_m: 0.9030\n",
            "Epoch 54/100\n",
            "11015/11015 [==============================] - 3s 252us/step - loss: 1.6823 - acc: 0.8915 - f1_m: 0.9046\n",
            "Epoch 55/100\n",
            "11015/11015 [==============================] - 2s 225us/step - loss: 1.6640 - acc: 0.8920 - f1_m: 0.9048\n",
            "Epoch 56/100\n",
            "11015/11015 [==============================] - 3s 240us/step - loss: 1.6588 - acc: 0.8921 - f1_m: 0.9048\n",
            "Epoch 57/100\n",
            "11015/11015 [==============================] - 3s 238us/step - loss: 1.6463 - acc: 0.8941 - f1_m: 0.9071\n",
            "Epoch 58/100\n",
            "11015/11015 [==============================] - 3s 231us/step - loss: 1.6565 - acc: 0.8911 - f1_m: 0.9046\n",
            "Epoch 59/100\n",
            "11015/11015 [==============================] - 3s 234us/step - loss: 1.2023 - acc: 0.9178 - f1_m: 0.9317\n",
            "Epoch 60/100\n",
            "11015/11015 [==============================] - 3s 253us/step - loss: 1.6390 - acc: 0.8925 - f1_m: 0.9056\n",
            "Epoch 61/100\n",
            "11015/11015 [==============================] - 2s 224us/step - loss: 1.6278 - acc: 0.8936 - f1_m: 0.9059\n",
            "Epoch 62/100\n",
            "11015/11015 [==============================] - 3s 236us/step - loss: 1.5839 - acc: 0.8937 - f1_m: 0.9070\n",
            "Epoch 63/100\n",
            "11015/11015 [==============================] - 3s 240us/step - loss: 1.4783 - acc: 0.9022 - f1_m: 0.9150\n",
            "Epoch 64/100\n",
            "11015/11015 [==============================] - 2s 213us/step - loss: 1.5059 - acc: 0.8996 - f1_m: 0.9124\n",
            "Epoch 65/100\n",
            "11015/11015 [==============================] - 3s 243us/step - loss: 1.5037 - acc: 0.9000 - f1_m: 0.9130\n",
            "Epoch 66/100\n",
            "11015/11015 [==============================] - 3s 235us/step - loss: 1.4677 - acc: 0.9032 - f1_m: 0.9161\n",
            "Epoch 67/100\n",
            "11015/11015 [==============================] - 3s 244us/step - loss: 1.4775 - acc: 0.8999 - f1_m: 0.9129\n",
            "Epoch 68/100\n",
            "11015/11015 [==============================] - 3s 233us/step - loss: 1.1642 - acc: 0.9173 - f1_m: 0.9312\n",
            "Epoch 69/100\n",
            "11015/11015 [==============================] - 3s 247us/step - loss: 1.2855 - acc: 0.9074 - f1_m: 0.9197\n",
            "Epoch 70/100\n",
            "11015/11015 [==============================] - 3s 233us/step - loss: 1.4815 - acc: 0.8931 - f1_m: 0.9047\n",
            "Epoch 71/100\n",
            "11015/11015 [==============================] - 2s 224us/step - loss: 1.3940 - acc: 0.8995 - f1_m: 0.9125\n",
            "Epoch 72/100\n",
            "11015/11015 [==============================] - 2s 216us/step - loss: 1.2153 - acc: 0.9140 - f1_m: 0.9266\n",
            "Epoch 73/100\n",
            "11015/11015 [==============================] - 3s 233us/step - loss: 1.3062 - acc: 0.9044 - f1_m: 0.9163\n",
            "Epoch 74/100\n",
            "11015/11015 [==============================] - 2s 208us/step - loss: 0.8638 - acc: 0.9376 - f1_m: 0.9474\n",
            "Epoch 75/100\n",
            "11015/11015 [==============================] - 2s 215us/step - loss: 0.8596 - acc: 0.9386 - f1_m: 0.9482\n",
            "Epoch 76/100\n",
            "11015/11015 [==============================] - 2s 217us/step - loss: 0.8810 - acc: 0.9335 - f1_m: 0.9443\n",
            "Epoch 77/100\n",
            "11015/11015 [==============================] - 3s 233us/step - loss: 0.8022 - acc: 0.9423 - f1_m: 0.9514\n",
            "Epoch 78/100\n",
            "11015/11015 [==============================] - 3s 233us/step - loss: 0.9506 - acc: 0.9272 - f1_m: 0.9401\n",
            "Epoch 79/100\n",
            "11015/11015 [==============================] - 2s 225us/step - loss: 0.8259 - acc: 0.9406 - f1_m: 0.9502\n",
            "Epoch 80/100\n",
            "11015/11015 [==============================] - 2s 211us/step - loss: 0.7948 - acc: 0.9404 - f1_m: 0.9499\n",
            "Epoch 81/100\n",
            "11015/11015 [==============================] - 3s 237us/step - loss: 0.7835 - acc: 0.9395 - f1_m: 0.9491\n",
            "Epoch 82/100\n",
            "11015/11015 [==============================] - 2s 216us/step - loss: 1.2074 - acc: 0.9149 - f1_m: 0.9258\n",
            "Epoch 83/100\n",
            "11015/11015 [==============================] - 2s 220us/step - loss: 1.1380 - acc: 0.9186 - f1_m: 0.9304\n",
            "Epoch 84/100\n",
            "11015/11015 [==============================] - 3s 241us/step - loss: 0.7599 - acc: 0.9402 - f1_m: 0.9501\n",
            "Epoch 85/100\n",
            "11015/11015 [==============================] - 2s 226us/step - loss: 0.7447 - acc: 0.9396 - f1_m: 0.9496\n",
            "Epoch 86/100\n",
            "11015/11015 [==============================] - 3s 229us/step - loss: 0.7204 - acc: 0.9411 - f1_m: 0.9507\n",
            "Epoch 87/100\n",
            "11015/11015 [==============================] - 2s 206us/step - loss: 0.7302 - acc: 0.9341 - f1_m: 0.9442\n",
            "Epoch 88/100\n",
            "11015/11015 [==============================] - 2s 217us/step - loss: 0.7041 - acc: 0.9423 - f1_m: 0.9514\n",
            "Epoch 89/100\n",
            "11015/11015 [==============================] - 2s 219us/step - loss: 0.6975 - acc: 0.9416 - f1_m: 0.9512\n",
            "Epoch 90/100\n",
            "11015/11015 [==============================] - 2s 224us/step - loss: 0.6934 - acc: 0.9463 - f1_m: 0.9549\n",
            "Epoch 91/100\n",
            "11015/11015 [==============================] - 2s 223us/step - loss: 0.7046 - acc: 0.9422 - f1_m: 0.9516\n",
            "Epoch 92/100\n",
            "11015/11015 [==============================] - 2s 222us/step - loss: 0.6807 - acc: 0.9471 - f1_m: 0.9556\n",
            "Epoch 93/100\n",
            "11015/11015 [==============================] - 2s 225us/step - loss: 0.6876 - acc: 0.9455 - f1_m: 0.9543\n",
            "Epoch 94/100\n",
            "11015/11015 [==============================] - 3s 231us/step - loss: 0.6752 - acc: 0.9481 - f1_m: 0.9559\n",
            "Epoch 95/100\n",
            "11015/11015 [==============================] - 2s 221us/step - loss: 0.7572 - acc: 0.9428 - f1_m: 0.9523\n",
            "Epoch 96/100\n",
            "11015/11015 [==============================] - 2s 221us/step - loss: 0.8293 - acc: 0.9351 - f1_m: 0.9450\n",
            "Epoch 97/100\n",
            "11015/11015 [==============================] - 2s 222us/step - loss: 0.7411 - acc: 0.9353 - f1_m: 0.9455\n",
            "Epoch 98/100\n",
            "11015/11015 [==============================] - 2s 209us/step - loss: 0.7199 - acc: 0.9332 - f1_m: 0.9435\n",
            "Epoch 99/100\n",
            "11015/11015 [==============================] - 2s 222us/step - loss: 0.7501 - acc: 0.9329 - f1_m: 0.9430\n",
            "Epoch 100/100\n",
            "11015/11015 [==============================] - 3s 227us/step - loss: 0.7145 - acc: 0.9379 - f1_m: 0.9472\n",
            "3672/3672 [==============================] - 1s 138us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4117: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_11 (InputLayer)           (None, 768)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_36 (Dense)                (None, 256)          196864      input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_37 (Dense)                (None, 256)          65792       dense_36[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_38 (Dense)                (None, 256)          65792       dense_37[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_12 (InputLayer)           (None, 32)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_39 (Dense)                (None, 32)           8224        dense_38[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 64)           0           input_12[0][0]                   \n",
            "                                                                 dense_39[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_40 (Dense)                (None, 32)           2080        concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_41 (Dense)                (None, 16)           528         dense_40[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_42 (Dense)                (None, 1)            17          dense_41[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 339,297\n",
            "Trainable params: 339,297\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "11015/11015 [==============================] - 3s 299us/step - loss: 2.6461 - acc: 0.8202 - f1_m: 0.8554\n",
            "Epoch 2/100\n",
            "11015/11015 [==============================] - 2s 226us/step - loss: 2.0127 - acc: 0.8676 - f1_m: 0.8816\n",
            "Epoch 3/100\n",
            "11015/11015 [==============================] - 3s 249us/step - loss: 1.9924 - acc: 0.8689 - f1_m: 0.8831\n",
            "Epoch 4/100\n",
            "11015/11015 [==============================] - 3s 228us/step - loss: 1.9911 - acc: 0.8674 - f1_m: 0.8818\n",
            "Epoch 5/100\n",
            "11015/11015 [==============================] - 3s 237us/step - loss: 1.9891 - acc: 0.8676 - f1_m: 0.8828\n",
            "Epoch 6/100\n",
            "11015/11015 [==============================] - 2s 227us/step - loss: 1.9699 - acc: 0.8701 - f1_m: 0.8845\n",
            "Epoch 7/100\n",
            "11015/11015 [==============================] - 3s 238us/step - loss: 1.9659 - acc: 0.8710 - f1_m: 0.8845\n",
            "Epoch 8/100\n",
            "11015/11015 [==============================] - 2s 227us/step - loss: 1.9526 - acc: 0.8736 - f1_m: 0.8868\n",
            "Epoch 9/100\n",
            "11015/11015 [==============================] - 2s 215us/step - loss: 1.9445 - acc: 0.8744 - f1_m: 0.8876\n",
            "Epoch 10/100\n",
            "11015/11015 [==============================] - 3s 234us/step - loss: 1.9406 - acc: 0.8754 - f1_m: 0.8883\n",
            "Epoch 11/100\n",
            "11015/11015 [==============================] - 2s 219us/step - loss: 1.9879 - acc: 0.8698 - f1_m: 0.8839\n",
            "Epoch 12/100\n",
            "11015/11015 [==============================] - 3s 230us/step - loss: 1.9980 - acc: 0.8704 - f1_m: 0.8848\n",
            "Epoch 13/100\n",
            "11015/11015 [==============================] - 3s 242us/step - loss: 1.9464 - acc: 0.8741 - f1_m: 0.8880\n",
            "Epoch 14/100\n",
            "11015/11015 [==============================] - 3s 229us/step - loss: 1.9605 - acc: 0.8734 - f1_m: 0.8880\n",
            "Epoch 15/100\n",
            "11015/11015 [==============================] - 3s 229us/step - loss: 1.9709 - acc: 0.8712 - f1_m: 0.8858\n",
            "Epoch 16/100\n",
            "11015/11015 [==============================] - 2s 218us/step - loss: 1.8983 - acc: 0.8772 - f1_m: 0.8945\n",
            "Epoch 17/100\n",
            "11015/11015 [==============================] - 3s 234us/step - loss: 1.7513 - acc: 0.8863 - f1_m: 0.9016\n",
            "Epoch 18/100\n",
            "11015/11015 [==============================] - 2s 221us/step - loss: 1.9069 - acc: 0.8758 - f1_m: 0.9000\n",
            "Epoch 19/100\n",
            "11015/11015 [==============================] - 2s 224us/step - loss: 1.7059 - acc: 0.8892 - f1_m: 0.9054\n",
            "Epoch 20/100\n",
            "11015/11015 [==============================] - 2s 225us/step - loss: 1.5568 - acc: 0.8988 - f1_m: 0.9133\n",
            "Epoch 21/100\n",
            "11015/11015 [==============================] - 2s 223us/step - loss: 1.7089 - acc: 0.8879 - f1_m: 0.9014\n",
            "Epoch 22/100\n",
            "11015/11015 [==============================] - 3s 227us/step - loss: 1.7082 - acc: 0.8884 - f1_m: 0.9016\n",
            "Epoch 23/100\n",
            "11015/11015 [==============================] - 2s 218us/step - loss: 1.7831 - acc: 0.8840 - f1_m: 0.9014\n",
            "Epoch 24/100\n",
            "11015/11015 [==============================] - 2s 220us/step - loss: 1.7115 - acc: 0.8868 - f1_m: 0.9086\n",
            "Epoch 25/100\n",
            "11015/11015 [==============================] - 3s 227us/step - loss: 1.5064 - acc: 0.9008 - f1_m: 0.9154\n",
            "Epoch 26/100\n",
            "11015/11015 [==============================] - 2s 210us/step - loss: 1.7111 - acc: 0.8893 - f1_m: 0.9025\n",
            "Epoch 27/100\n",
            "11015/11015 [==============================] - 3s 228us/step - loss: 1.7147 - acc: 0.8892 - f1_m: 0.9020\n",
            "Epoch 28/100\n",
            "11015/11015 [==============================] - 3s 231us/step - loss: 1.7106 - acc: 0.8900 - f1_m: 0.9026\n",
            "Epoch 29/100\n",
            "11015/11015 [==============================] - 3s 230us/step - loss: 1.7047 - acc: 0.8898 - f1_m: 0.9020\n",
            "Epoch 30/100\n",
            "11015/11015 [==============================] - 3s 248us/step - loss: 1.6724 - acc: 0.8905 - f1_m: 0.9042\n",
            "Epoch 31/100\n",
            "11015/11015 [==============================] - 3s 235us/step - loss: 1.6735 - acc: 0.8921 - f1_m: 0.9053\n",
            "Epoch 32/100\n",
            "11015/11015 [==============================] - 3s 232us/step - loss: 1.6630 - acc: 0.8930 - f1_m: 0.9063\n",
            "Epoch 33/100\n",
            "11015/11015 [==============================] - 3s 231us/step - loss: 1.5942 - acc: 0.8948 - f1_m: 0.9090\n",
            "Epoch 34/100\n",
            "11015/11015 [==============================] - 2s 206us/step - loss: 1.6745 - acc: 0.8920 - f1_m: 0.9047\n",
            "Epoch 35/100\n",
            "11015/11015 [==============================] - 3s 243us/step - loss: 1.6708 - acc: 0.8917 - f1_m: 0.9042\n",
            "Epoch 36/100\n",
            "11015/11015 [==============================] - 3s 230us/step - loss: 1.6715 - acc: 0.8913 - f1_m: 0.9050\n",
            "Epoch 37/100\n",
            "11015/11015 [==============================] - 2s 225us/step - loss: 1.6681 - acc: 0.8917 - f1_m: 0.9046\n",
            "Epoch 38/100\n",
            "11015/11015 [==============================] - 2s 207us/step - loss: 1.6617 - acc: 0.8920 - f1_m: 0.9046\n",
            "Epoch 39/100\n",
            "11015/11015 [==============================] - 3s 236us/step - loss: 1.6617 - acc: 0.8924 - f1_m: 0.9057\n",
            "Epoch 40/100\n",
            "11015/11015 [==============================] - 3s 229us/step - loss: 1.6802 - acc: 0.8911 - f1_m: 0.9044\n",
            "Epoch 41/100\n",
            "11015/11015 [==============================] - 2s 226us/step - loss: 1.6760 - acc: 0.8916 - f1_m: 0.9046\n",
            "Epoch 42/100\n",
            "11015/11015 [==============================] - 3s 228us/step - loss: 1.6610 - acc: 0.8925 - f1_m: 0.9049\n",
            "Epoch 43/100\n",
            "11015/11015 [==============================] - 3s 242us/step - loss: 1.6489 - acc: 0.8936 - f1_m: 0.9072\n",
            "Epoch 44/100\n",
            "11015/11015 [==============================] - 2s 226us/step - loss: 1.6598 - acc: 0.8916 - f1_m: 0.9059\n",
            "Epoch 45/100\n",
            "11015/11015 [==============================] - 2s 222us/step - loss: 1.6772 - acc: 0.8898 - f1_m: 0.9032\n",
            "Epoch 46/100\n",
            "11015/11015 [==============================] - 2s 210us/step - loss: 1.6708 - acc: 0.8920 - f1_m: 0.9044\n",
            "Epoch 47/100\n",
            "11015/11015 [==============================] - 3s 248us/step - loss: 1.6671 - acc: 0.8921 - f1_m: 0.9049\n",
            "Epoch 48/100\n",
            "11015/11015 [==============================] - 2s 223us/step - loss: 1.6407 - acc: 0.8911 - f1_m: 0.9091\n",
            "Epoch 49/100\n",
            "11015/11015 [==============================] - 2s 227us/step - loss: 1.8014 - acc: 0.8813 - f1_m: 0.8983\n",
            "Epoch 50/100\n",
            "11015/11015 [==============================] - 3s 250us/step - loss: 1.9623 - acc: 0.8724 - f1_m: 0.8877\n",
            "Epoch 51/100\n",
            "11015/11015 [==============================] - 3s 254us/step - loss: 1.7290 - acc: 0.8861 - f1_m: 0.9000\n",
            "Epoch 52/100\n",
            "11015/11015 [==============================] - 3s 240us/step - loss: 1.5149 - acc: 0.8970 - f1_m: 0.9118\n",
            "Epoch 53/100\n",
            "11015/11015 [==============================] - 2s 223us/step - loss: 1.3105 - acc: 0.9095 - f1_m: 0.9232\n",
            "Epoch 54/100\n",
            "11015/11015 [==============================] - 3s 245us/step - loss: 1.1746 - acc: 0.9182 - f1_m: 0.9307\n",
            "Epoch 55/100\n",
            "11015/11015 [==============================] - 2s 227us/step - loss: 1.1584 - acc: 0.9210 - f1_m: 0.9332\n",
            "Epoch 56/100\n",
            "11015/11015 [==============================] - 2s 218us/step - loss: 1.6070 - acc: 0.8935 - f1_m: 0.9060\n",
            "Epoch 57/100\n",
            "11015/11015 [==============================] - 3s 240us/step - loss: 1.6729 - acc: 0.8899 - f1_m: 0.9025\n",
            "Epoch 58/100\n",
            "11015/11015 [==============================] - 2s 224us/step - loss: 1.5652 - acc: 0.8967 - f1_m: 0.9103\n",
            "Epoch 59/100\n",
            "11015/11015 [==============================] - 2s 218us/step - loss: 1.3557 - acc: 0.9104 - f1_m: 0.9221\n",
            "Epoch 60/100\n",
            "11015/11015 [==============================] - 2s 215us/step - loss: 1.5661 - acc: 0.8951 - f1_m: 0.9081\n",
            "Epoch 61/100\n",
            "11015/11015 [==============================] - 2s 222us/step - loss: 1.6778 - acc: 0.8901 - f1_m: 0.9033\n",
            "Epoch 62/100\n",
            "11015/11015 [==============================] - 3s 227us/step - loss: 1.6567 - acc: 0.8920 - f1_m: 0.9047\n",
            "Epoch 63/100\n",
            "11015/11015 [==============================] - 2s 210us/step - loss: 1.6551 - acc: 0.8920 - f1_m: 0.9047\n",
            "Epoch 64/100\n",
            "11015/11015 [==============================] - 3s 236us/step - loss: 1.6657 - acc: 0.8908 - f1_m: 0.9042\n",
            "Epoch 65/100\n",
            "11015/11015 [==============================] - 3s 239us/step - loss: 1.6545 - acc: 0.8923 - f1_m: 0.9053\n",
            "Epoch 66/100\n",
            "11015/11015 [==============================] - 2s 227us/step - loss: 1.6525 - acc: 0.8917 - f1_m: 0.9040\n",
            "Epoch 67/100\n",
            "11015/11015 [==============================] - 2s 223us/step - loss: 1.6494 - acc: 0.8928 - f1_m: 0.9056\n",
            "Epoch 68/100\n",
            "11015/11015 [==============================] - 2s 212us/step - loss: 1.6501 - acc: 0.8928 - f1_m: 0.9054\n",
            "Epoch 69/100\n",
            "11015/11015 [==============================] - 2s 219us/step - loss: 1.6422 - acc: 0.8939 - f1_m: 0.9061\n",
            "Epoch 70/100\n",
            "11015/11015 [==============================] - 3s 231us/step - loss: 1.6439 - acc: 0.8939 - f1_m: 0.9067\n",
            "Epoch 71/100\n",
            "11015/11015 [==============================] - 2s 224us/step - loss: 1.6476 - acc: 0.8924 - f1_m: 0.9048\n",
            "Epoch 72/100\n",
            "11015/11015 [==============================] - 3s 236us/step - loss: 1.5850 - acc: 0.8932 - f1_m: 0.9062\n",
            "Epoch 73/100\n",
            "11015/11015 [==============================] - 3s 242us/step - loss: 1.6619 - acc: 0.8864 - f1_m: 0.9003\n",
            "Epoch 74/100\n",
            "11015/11015 [==============================] - 2s 225us/step - loss: 1.6637 - acc: 0.8912 - f1_m: 0.9042\n",
            "Epoch 75/100\n",
            "11015/11015 [==============================] - 3s 232us/step - loss: 1.6634 - acc: 0.8915 - f1_m: 0.9046\n",
            "Epoch 76/100\n",
            "11015/11015 [==============================] - 3s 227us/step - loss: 1.6465 - acc: 0.8917 - f1_m: 0.9044\n",
            "Epoch 77/100\n",
            "11015/11015 [==============================] - 3s 233us/step - loss: 1.6260 - acc: 0.8931 - f1_m: 0.9066\n",
            "Epoch 78/100\n",
            "11015/11015 [==============================] - 2s 222us/step - loss: 1.5466 - acc: 0.8980 - f1_m: 0.9113\n",
            "Epoch 79/100\n",
            "11015/11015 [==============================] - 2s 219us/step - loss: 1.1040 - acc: 0.9226 - f1_m: 0.9354\n",
            "Epoch 80/100\n",
            "11015/11015 [==============================] - 3s 232us/step - loss: 1.0633 - acc: 0.9245 - f1_m: 0.9362\n",
            "Epoch 81/100\n",
            "11015/11015 [==============================] - 3s 234us/step - loss: 1.1513 - acc: 0.9224 - f1_m: 0.9350\n",
            "Epoch 82/100\n",
            "11015/11015 [==============================] - 2s 224us/step - loss: 1.0884 - acc: 0.9262 - f1_m: 0.9378\n",
            "Epoch 83/100\n",
            "11015/11015 [==============================] - 3s 228us/step - loss: 1.0876 - acc: 0.9261 - f1_m: 0.9367\n",
            "Epoch 84/100\n",
            "11015/11015 [==============================] - 2s 223us/step - loss: 1.3922 - acc: 0.9074 - f1_m: 0.9203\n",
            "Epoch 85/100\n",
            "11015/11015 [==============================] - 2s 213us/step - loss: 1.0627 - acc: 0.9248 - f1_m: 0.9367\n",
            "Epoch 86/100\n",
            "11015/11015 [==============================] - 2s 216us/step - loss: 0.9337 - acc: 0.9318 - f1_m: 0.9425\n",
            "Epoch 87/100\n",
            "11015/11015 [==============================] - 3s 248us/step - loss: 0.9237 - acc: 0.9319 - f1_m: 0.9416\n",
            "Epoch 88/100\n",
            "11015/11015 [==============================] - 3s 241us/step - loss: 0.9882 - acc: 0.9284 - f1_m: 0.9387\n",
            "Epoch 89/100\n",
            "11015/11015 [==============================] - 3s 240us/step - loss: 1.1780 - acc: 0.8970 - f1_m: 0.9114\n",
            "Epoch 90/100\n",
            "11015/11015 [==============================] - 2s 214us/step - loss: 0.9129 - acc: 0.8944 - f1_m: 0.9096\n",
            "Epoch 91/100\n",
            "11015/11015 [==============================] - 3s 232us/step - loss: 0.8710 - acc: 0.8984 - f1_m: 0.9117\n",
            "Epoch 92/100\n",
            "11015/11015 [==============================] - 2s 221us/step - loss: 0.8218 - acc: 0.8999 - f1_m: 0.9127\n",
            "Epoch 93/100\n",
            "11015/11015 [==============================] - 2s 215us/step - loss: 0.8193 - acc: 0.8953 - f1_m: 0.9091\n",
            "Epoch 94/100\n",
            "11015/11015 [==============================] - 2s 217us/step - loss: 0.7348 - acc: 0.9057 - f1_m: 0.9195\n",
            "Epoch 95/100\n",
            "11015/11015 [==============================] - 3s 251us/step - loss: 0.7647 - acc: 0.9055 - f1_m: 0.9185\n",
            "Epoch 96/100\n",
            "11015/11015 [==============================] - 3s 229us/step - loss: 0.7758 - acc: 0.9042 - f1_m: 0.9175\n",
            "Epoch 97/100\n",
            "11015/11015 [==============================] - 3s 230us/step - loss: 0.7448 - acc: 0.9057 - f1_m: 0.9181\n",
            "Epoch 98/100\n",
            "11015/11015 [==============================] - 2s 220us/step - loss: 0.4283 - acc: 0.9021 - f1_m: 0.9180\n",
            "Epoch 99/100\n",
            "11015/11015 [==============================] - 2s 222us/step - loss: 0.2531 - acc: 0.9181 - f1_m: 0.9326\n",
            "Epoch 100/100\n",
            "11015/11015 [==============================] - 2s 206us/step - loss: 0.2507 - acc: 0.9195 - f1_m: 0.9342\n",
            "3672/3672 [==============================] - 1s 143us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4117: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_13 (InputLayer)           (None, 768)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_43 (Dense)                (None, 256)          196864      input_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_44 (Dense)                (None, 256)          65792       dense_43[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_45 (Dense)                (None, 256)          65792       dense_44[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_14 (InputLayer)           (None, 32)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_46 (Dense)                (None, 32)           8224        dense_45[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 64)           0           input_14[0][0]                   \n",
            "                                                                 dense_46[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_47 (Dense)                (None, 32)           2080        concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_48 (Dense)                (None, 16)           528         dense_47[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_49 (Dense)                (None, 1)            17          dense_48[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 339,297\n",
            "Trainable params: 339,297\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "11015/11015 [==============================] - 4s 321us/step - loss: 2.4608 - acc: 0.8321 - f1_m: 0.8399\n",
            "Epoch 2/100\n",
            "11015/11015 [==============================] - 3s 228us/step - loss: 2.0158 - acc: 0.8635 - f1_m: 0.8791\n",
            "Epoch 3/100\n",
            "11015/11015 [==============================] - 3s 228us/step - loss: 2.0087 - acc: 0.8635 - f1_m: 0.8793\n",
            "Epoch 4/100\n",
            "11015/11015 [==============================] - 3s 237us/step - loss: 1.9674 - acc: 0.8712 - f1_m: 0.8857\n",
            "Epoch 5/100\n",
            "11015/11015 [==============================] - 3s 234us/step - loss: 1.9417 - acc: 0.8732 - f1_m: 0.8862\n",
            "Epoch 6/100\n",
            "11015/11015 [==============================] - 2s 227us/step - loss: 1.9804 - acc: 0.8702 - f1_m: 0.8835\n",
            "Epoch 7/100\n",
            "11015/11015 [==============================] - 2s 225us/step - loss: 1.9686 - acc: 0.8725 - f1_m: 0.8866\n",
            "Epoch 8/100\n",
            "11015/11015 [==============================] - 3s 227us/step - loss: 1.9769 - acc: 0.8725 - f1_m: 0.8850\n",
            "Epoch 9/100\n",
            "11015/11015 [==============================] - 3s 229us/step - loss: 1.9429 - acc: 0.8744 - f1_m: 0.8876\n",
            "Epoch 10/100\n",
            "11015/11015 [==============================] - 2s 217us/step - loss: 1.9358 - acc: 0.8759 - f1_m: 0.8890\n",
            "Epoch 11/100\n",
            "11015/11015 [==============================] - 2s 221us/step - loss: 2.2256 - acc: 0.8538 - f1_m: 0.8742\n",
            "Epoch 12/100\n",
            "11015/11015 [==============================] - 3s 236us/step - loss: 1.9373 - acc: 0.8734 - f1_m: 0.8867\n",
            "Epoch 13/100\n",
            "11015/11015 [==============================] - 3s 247us/step - loss: 1.9231 - acc: 0.8768 - f1_m: 0.8901\n",
            "Epoch 14/100\n",
            "11015/11015 [==============================] - 2s 216us/step - loss: 1.9229 - acc: 0.8771 - f1_m: 0.8902\n",
            "Epoch 15/100\n",
            "11015/11015 [==============================] - 2s 219us/step - loss: 2.0421 - acc: 0.8675 - f1_m: 0.8870\n",
            "Epoch 16/100\n",
            "11015/11015 [==============================] - 3s 239us/step - loss: 1.7029 - acc: 0.8897 - f1_m: 0.9026\n",
            "Epoch 17/100\n",
            "11015/11015 [==============================] - 2s 221us/step - loss: 1.6871 - acc: 0.8918 - f1_m: 0.9044\n",
            "Epoch 18/100\n",
            "11015/11015 [==============================] - 2s 219us/step - loss: 1.6915 - acc: 0.8910 - f1_m: 0.9040\n",
            "Epoch 19/100\n",
            "11015/11015 [==============================] - 2s 206us/step - loss: 1.8188 - acc: 0.8815 - f1_m: 0.9001\n",
            "Epoch 20/100\n",
            "11015/11015 [==============================] - 2s 222us/step - loss: 1.7746 - acc: 0.8860 - f1_m: 0.9057\n",
            "Epoch 21/100\n",
            "11015/11015 [==============================] - 3s 237us/step - loss: 1.5732 - acc: 0.8954 - f1_m: 0.9115\n",
            "Epoch 22/100\n",
            "11015/11015 [==============================] - 2s 220us/step - loss: 1.6942 - acc: 0.8909 - f1_m: 0.9047\n",
            "Epoch 23/100\n",
            "11015/11015 [==============================] - 3s 239us/step - loss: 1.6761 - acc: 0.8924 - f1_m: 0.9051\n",
            "Epoch 24/100\n",
            "11015/11015 [==============================] - 3s 238us/step - loss: 1.6693 - acc: 0.8934 - f1_m: 0.9058\n",
            "Epoch 25/100\n",
            "11015/11015 [==============================] - 3s 227us/step - loss: 1.6750 - acc: 0.8927 - f1_m: 0.9058\n",
            "Epoch 26/100\n",
            "11015/11015 [==============================] - 2s 211us/step - loss: 1.6738 - acc: 0.8917 - f1_m: 0.9046\n",
            "Epoch 27/100\n",
            "11015/11015 [==============================] - 2s 224us/step - loss: 1.6671 - acc: 0.8934 - f1_m: 0.9062\n",
            "Epoch 28/100\n",
            "11015/11015 [==============================] - 2s 214us/step - loss: 1.6799 - acc: 0.8924 - f1_m: 0.9057\n",
            "Epoch 29/100\n",
            "11015/11015 [==============================] - 2s 222us/step - loss: 1.6768 - acc: 0.8920 - f1_m: 0.9043\n",
            "Epoch 30/100\n",
            "11015/11015 [==============================] - 2s 213us/step - loss: 1.6716 - acc: 0.8922 - f1_m: 0.9045\n",
            "Epoch 31/100\n",
            "11015/11015 [==============================] - 3s 244us/step - loss: 1.6701 - acc: 0.8921 - f1_m: 0.9045\n",
            "Epoch 32/100\n",
            "11015/11015 [==============================] - 3s 230us/step - loss: 1.6625 - acc: 0.8934 - f1_m: 0.9060\n",
            "Epoch 33/100\n",
            "11015/11015 [==============================] - 3s 234us/step - loss: 1.6570 - acc: 0.8937 - f1_m: 0.9059\n",
            "Epoch 34/100\n",
            "11015/11015 [==============================] - 3s 234us/step - loss: 1.6605 - acc: 0.8940 - f1_m: 0.9058\n",
            "Epoch 35/100\n",
            "11015/11015 [==============================] - 2s 225us/step - loss: 1.6675 - acc: 0.8934 - f1_m: 0.9055\n",
            "Epoch 36/100\n",
            "11015/11015 [==============================] - 2s 219us/step - loss: 1.6593 - acc: 0.8944 - f1_m: 0.9066\n",
            "Epoch 37/100\n",
            "11015/11015 [==============================] - 3s 230us/step - loss: 1.6622 - acc: 0.8933 - f1_m: 0.9062\n",
            "Epoch 38/100\n",
            "11015/11015 [==============================] - 3s 230us/step - loss: 1.6602 - acc: 0.8940 - f1_m: 0.9059\n",
            "Epoch 39/100\n",
            "11015/11015 [==============================] - 2s 218us/step - loss: 1.6693 - acc: 0.8928 - f1_m: 0.9063\n",
            "Epoch 40/100\n",
            "11015/11015 [==============================] - 2s 215us/step - loss: 1.6561 - acc: 0.8950 - f1_m: 0.9080\n",
            "Epoch 41/100\n",
            "11015/11015 [==============================] - 2s 215us/step - loss: 1.6609 - acc: 0.8934 - f1_m: 0.9058\n",
            "Epoch 42/100\n",
            "11015/11015 [==============================] - 2s 214us/step - loss: 1.6534 - acc: 0.8925 - f1_m: 0.9057\n",
            "Epoch 43/100\n",
            "11015/11015 [==============================] - 3s 229us/step - loss: 1.6511 - acc: 0.8936 - f1_m: 0.9061\n",
            "Epoch 44/100\n",
            "11015/11015 [==============================] - 3s 234us/step - loss: 1.6462 - acc: 0.8941 - f1_m: 0.9065\n",
            "Epoch 45/100\n",
            "11015/11015 [==============================] - 2s 215us/step - loss: 1.6857 - acc: 0.8903 - f1_m: 0.9049\n",
            "Epoch 46/100\n",
            "11015/11015 [==============================] - 3s 254us/step - loss: 1.6961 - acc: 0.8879 - f1_m: 0.9014\n",
            "Epoch 47/100\n",
            "11015/11015 [==============================] - 3s 235us/step - loss: 1.6341 - acc: 0.8951 - f1_m: 0.9086\n",
            "Epoch 48/100\n",
            "11015/11015 [==============================] - 3s 235us/step - loss: 1.6482 - acc: 0.8939 - f1_m: 0.9069\n",
            "Epoch 49/100\n",
            "11015/11015 [==============================] - 3s 238us/step - loss: 1.6534 - acc: 0.8928 - f1_m: 0.9055\n",
            "Epoch 50/100\n",
            "11015/11015 [==============================] - 3s 231us/step - loss: 1.6352 - acc: 0.8948 - f1_m: 0.9072\n",
            "Epoch 51/100\n",
            "11015/11015 [==============================] - 2s 204us/step - loss: 1.6093 - acc: 0.8952 - f1_m: 0.9090\n",
            "Epoch 52/100\n",
            "11015/11015 [==============================] - 2s 220us/step - loss: 1.6255 - acc: 0.8954 - f1_m: 0.9085\n",
            "Epoch 53/100\n",
            "11015/11015 [==============================] - 3s 244us/step - loss: 1.7827 - acc: 0.8836 - f1_m: 0.9020\n",
            "Epoch 54/100\n",
            "11015/11015 [==============================] - 3s 241us/step - loss: 1.6844 - acc: 0.8914 - f1_m: 0.9083\n",
            "Epoch 55/100\n",
            "11015/11015 [==============================] - 2s 223us/step - loss: 1.3667 - acc: 0.9097 - f1_m: 0.9246\n",
            "Epoch 56/100\n",
            "11015/11015 [==============================] - 3s 238us/step - loss: 1.6519 - acc: 0.8939 - f1_m: 0.9073\n",
            "Epoch 57/100\n",
            "11015/11015 [==============================] - 3s 245us/step - loss: 1.5225 - acc: 0.9012 - f1_m: 0.9147\n",
            "Epoch 58/100\n",
            "11015/11015 [==============================] - 2s 216us/step - loss: 1.3530 - acc: 0.9119 - f1_m: 0.9241\n",
            "Epoch 59/100\n",
            "11015/11015 [==============================] - 2s 218us/step - loss: 1.1877 - acc: 0.9213 - f1_m: 0.9339\n",
            "Epoch 60/100\n",
            "11015/11015 [==============================] - 3s 231us/step - loss: 1.2586 - acc: 0.9171 - f1_m: 0.9308\n",
            "Epoch 61/100\n",
            "11015/11015 [==============================] - 3s 239us/step - loss: 0.8781 - acc: 0.9413 - f1_m: 0.9515\n",
            "Epoch 62/100\n",
            "11015/11015 [==============================] - 2s 222us/step - loss: 0.9082 - acc: 0.9394 - f1_m: 0.9503\n",
            "Epoch 63/100\n",
            "11015/11015 [==============================] - 2s 225us/step - loss: 0.9920 - acc: 0.9334 - f1_m: 0.9464\n",
            "Epoch 64/100\n",
            "11015/11015 [==============================] - 2s 216us/step - loss: 1.5916 - acc: 0.8953 - f1_m: 0.9142\n",
            "Epoch 65/100\n",
            "11015/11015 [==============================] - 3s 233us/step - loss: 1.9400 - acc: 0.8747 - f1_m: 0.9042\n",
            "Epoch 66/100\n",
            "11015/11015 [==============================] - 3s 229us/step - loss: 1.3186 - acc: 0.9120 - f1_m: 0.9297\n",
            "Epoch 67/100\n",
            "11015/11015 [==============================] - 3s 233us/step - loss: 1.0325 - acc: 0.9283 - f1_m: 0.9402\n",
            "Epoch 68/100\n",
            "11015/11015 [==============================] - 3s 229us/step - loss: 0.8715 - acc: 0.9399 - f1_m: 0.9518\n",
            "Epoch 69/100\n",
            "11015/11015 [==============================] - 2s 226us/step - loss: 0.8480 - acc: 0.9418 - f1_m: 0.9521\n",
            "Epoch 70/100\n",
            "11015/11015 [==============================] - 2s 215us/step - loss: 0.9971 - acc: 0.9330 - f1_m: 0.9450\n",
            "Epoch 71/100\n",
            "11015/11015 [==============================] - 2s 214us/step - loss: 1.2129 - acc: 0.9192 - f1_m: 0.9301\n",
            "Epoch 72/100\n",
            "11015/11015 [==============================] - 3s 234us/step - loss: 0.8779 - acc: 0.9386 - f1_m: 0.9488\n",
            "Epoch 73/100\n",
            "11015/11015 [==============================] - 2s 226us/step - loss: 0.7355 - acc: 0.9490 - f1_m: 0.9576\n",
            "Epoch 74/100\n",
            "11015/11015 [==============================] - 2s 218us/step - loss: 1.0186 - acc: 0.9301 - f1_m: 0.9403\n",
            "Epoch 75/100\n",
            "11015/11015 [==============================] - 3s 251us/step - loss: 1.3282 - acc: 0.9121 - f1_m: 0.9248\n",
            "Epoch 76/100\n",
            "11015/11015 [==============================] - 3s 229us/step - loss: 0.8712 - acc: 0.9419 - f1_m: 0.9517\n",
            "Epoch 77/100\n",
            "11015/11015 [==============================] - 3s 233us/step - loss: 0.8347 - acc: 0.9450 - f1_m: 0.9537\n",
            "Epoch 78/100\n",
            "11015/11015 [==============================] - 2s 215us/step - loss: 0.8575 - acc: 0.9410 - f1_m: 0.9511\n",
            "Epoch 79/100\n",
            "11015/11015 [==============================] - 2s 220us/step - loss: 1.0618 - acc: 0.9263 - f1_m: 0.9387\n",
            "Epoch 80/100\n",
            "11015/11015 [==============================] - 2s 224us/step - loss: 1.7515 - acc: 0.8875 - f1_m: 0.9139\n",
            "Epoch 81/100\n",
            "11015/11015 [==============================] - 3s 244us/step - loss: 1.0054 - acc: 0.9320 - f1_m: 0.9432\n",
            "Epoch 82/100\n",
            "11015/11015 [==============================] - 2s 217us/step - loss: 0.6867 - acc: 0.9512 - f1_m: 0.9610\n",
            "Epoch 83/100\n",
            "11015/11015 [==============================] - 3s 242us/step - loss: 0.6521 - acc: 0.9547 - f1_m: 0.9638\n",
            "Epoch 84/100\n",
            "11015/11015 [==============================] - 3s 231us/step - loss: 0.7179 - acc: 0.9498 - f1_m: 0.9599\n",
            "Epoch 85/100\n",
            "11015/11015 [==============================] - 2s 220us/step - loss: 0.5385 - acc: 0.9620 - f1_m: 0.9698\n",
            "Epoch 86/100\n",
            "11015/11015 [==============================] - 2s 212us/step - loss: 0.5792 - acc: 0.9560 - f1_m: 0.9648\n",
            "Epoch 87/100\n",
            "11015/11015 [==============================] - 2s 219us/step - loss: 0.6411 - acc: 0.9525 - f1_m: 0.9611\n",
            "Epoch 88/100\n",
            "11015/11015 [==============================] - 2s 218us/step - loss: 0.4659 - acc: 0.9638 - f1_m: 0.9704\n",
            "Epoch 89/100\n",
            "11015/11015 [==============================] - 2s 212us/step - loss: 1.0340 - acc: 0.9274 - f1_m: 0.9432\n",
            "Epoch 90/100\n",
            "11015/11015 [==============================] - 3s 241us/step - loss: 0.7247 - acc: 0.9485 - f1_m: 0.9587\n",
            "Epoch 91/100\n",
            "11015/11015 [==============================] - 3s 231us/step - loss: 0.8724 - acc: 0.9394 - f1_m: 0.9493\n",
            "Epoch 92/100\n",
            "11015/11015 [==============================] - 2s 212us/step - loss: 0.7212 - acc: 0.9482 - f1_m: 0.9571\n",
            "Epoch 93/100\n",
            "11015/11015 [==============================] - 2s 201us/step - loss: 0.5162 - acc: 0.9592 - f1_m: 0.9665\n",
            "Epoch 94/100\n",
            "11015/11015 [==============================] - 2s 211us/step - loss: 0.5060 - acc: 0.9600 - f1_m: 0.9668\n",
            "Epoch 95/100\n",
            "11015/11015 [==============================] - 2s 222us/step - loss: 0.5208 - acc: 0.9586 - f1_m: 0.9662\n",
            "Epoch 96/100\n",
            "11015/11015 [==============================] - 3s 228us/step - loss: 0.5475 - acc: 0.9591 - f1_m: 0.9670\n",
            "Epoch 97/100\n",
            "11015/11015 [==============================] - 2s 218us/step - loss: 0.4242 - acc: 0.9664 - f1_m: 0.9732\n",
            "Epoch 98/100\n",
            "11015/11015 [==============================] - 3s 236us/step - loss: 0.5217 - acc: 0.9591 - f1_m: 0.9666\n",
            "Epoch 99/100\n",
            "11015/11015 [==============================] - 2s 223us/step - loss: 0.5054 - acc: 0.9594 - f1_m: 0.9667\n",
            "Epoch 100/100\n",
            "11015/11015 [==============================] - 2s 212us/step - loss: 0.5576 - acc: 0.9565 - f1_m: 0.9646\n",
            "3672/3672 [==============================] - 1s 164us/step\n",
            "(Loss, Accuracy, F1-score) after 5-fold cross validation [0.53244098 0.93801743 0.9483967 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtkjJ5QtJrqO",
        "colab_type": "text"
      },
      "source": [
        "As we can see, there is an significant increase in the results in the network using the semantic information (about 3% in both accuracy and f1-score)."
      ]
    }
  ]
}